import re
import requests
import time
import os
import json
from bridge.reply import Reply, ReplyType
from bridge.context import ContextType, Context
from common.log import logger
from plugins import register, Plugin, Event, EventContext, EventAction
from concurrent.futures import ThreadPoolExecutor
from functools import partial
import hashlib
import threading
from io import BytesIO
from PIL import Image
import io

@register(name="media_parser", desc="è§†é¢‘å›¾é›†è§£ææ’ä»¶", version="1.4", author="å®‰ä¸", desire_priority=100)
class MediaParserPlugin(Plugin):
    def __init__(self):
        super().__init__()
        self.handlers[Event.ON_HANDLE_CONTEXT] = self.on_handle_context
        
        # åˆå§‹åŒ–é…ç½®å’Œç¼“å­˜
        self._load_config()
        self._init_cache()
        
        # åˆå§‹åŒ–ä¼šè¯å’Œçº¿ç¨‹æ± 
        self.session = requests.Session()
        self.executor = ThreadPoolExecutor(max_workers=5)  # å¢åŠ çº¿ç¨‹æ± å¤§å°ä»¥æé«˜ä¸‹è½½æ•ˆç‡
        
        # çº¿ç¨‹é”ç”¨äºç¼“å­˜ç®¡ç†çš„åŒæ­¥
        self.cache_lock = threading.Lock()  # ç¡®ä¿è¿™è¡Œå­˜åœ¨
        self.tasks_lock = threading.Lock()
        
        # æ”¯æŒçš„æ–‡ä»¶ç±»å‹
        self.video_extensions = {
            'video/mp4': '.mp4',
            'video/x-flv': '.flv',
            'video/quicktime': '.mov',
            'video/x-ms-wmv': '.wmv',
            'video/x-msvideo': '.avi',
        }
        
        self.image_extensions = {
            'image/jpeg': '.jpg',
            'image/png': '.png',
            'image/gif': '.gif',
            'image/webp': '.webp',
            'image/bmp': '.bmp',
        }
        
        # è®°å½•æ­£åœ¨å¤„ç†çš„ä»»åŠ¡
        self.processing_tasks = {}
        
        # å¯åŠ¨åå°çº¿ç¨‹å¤„ç†å¾…å‘é€çš„ä»»åŠ¡
        self.stop_event = threading.Event()
        self.worker_thread = threading.Thread(target=self._process_pending_tasks, daemon=True)
        self.worker_thread.start()
        
        logger.info("[MediaParser] æ’ä»¶å·²åŠ è½½")

    def _load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        curdir = os.path.dirname(__file__)
        config_path = os.path.join(curdir, "config.json")
        
        self.default_config = {
            "api_endpoints": {
                "video": "https://www.hhlqilongzhu.cn/api/sp_jx/sp.php",
                "image": "https://www.hhlqilongzhu.cn/api/sp_jx/tuji.php"
            },
            "supported_platforms": [
                "æŠ–éŸ³",
                "å¿«æ‰‹",
                "å¾®åš",
                "å°çº¢ä¹¦"
            ],
            "cache": {
                "max_size_mb": 500,
                "max_age_hours": 24,
                "chunk_size": 8192
            },
            "download": {
                "timeout": 30,
                "max_retries": 3,
                "retry_delay": 1,
                "max_workers": 5
            },
            "batch": {
                "image_limit": 10,  # æ¯æ‰¹æœ€å¤šå‘é€çš„å›¾ç‰‡æ•°
                "delay_seconds": 2   # æ‰¹æ¬¡é—´å»¶è¿Ÿæ—¶é—´
            }
        }
        
        try:
            if os.path.exists(config_path):
                with open(config_path, "r", encoding="utf-8") as f:
                    config = json.load(f)
                self.config = self._merge_config(self.default_config, config)
            else:
                self.config = self.default_config
                with open(config_path, "w", encoding="utf-8") as f:
                    json.dump(self.config, f, indent=4, ensure_ascii=False)
        except Exception as e:
            logger.warn(f"[MediaParser] åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤é…ç½®")
            self.config = self.default_config
            
        # è®¾ç½®API endpoints
        self.video_api = self.config["api_endpoints"]["video"]
        self.image_api = self.config["api_endpoints"]["image"]
        self.supported_platforms = self.config.get("supported_platforms", [])

        # é…ç½®éªŒè¯
        self._validate_config()

    def _validate_config(self):
        """éªŒè¯é…ç½®æ–‡ä»¶çš„æœ‰æ•ˆæ€§"""
        try:
            assert isinstance(self.config["cache"]["max_size_mb"], (int, float)) and self.config["cache"]["max_size_mb"] > 0, "ç¼“å­˜å¤§å°é…ç½®é”™è¯¯"
            assert isinstance(self.config["cache"]["max_age_hours"], (int, float)) and self.config["cache"]["max_age_hours"] > 0, "ç¼“å­˜è¿‡æœŸæ—¶é—´é…ç½®é”™è¯¯"
            assert isinstance(self.config["download"]["timeout"], (int, float)) and self.config["download"]["timeout"] > 0, "ä¸‹è½½è¶…æ—¶é…ç½®é”™è¯¯"
            assert isinstance(self.config["download"]["max_retries"], int) and self.config["download"]["max_retries"] >= 0, "æœ€å¤§é‡è¯•æ¬¡æ•°é…ç½®é”™è¯¯"
            assert isinstance(self.config["download"]["retry_delay"], (int, float)) and self.config["download"]["retry_delay"] >= 0, "é‡è¯•å»¶è¿Ÿé…ç½®é”™è¯¯"
            assert isinstance(self.config["batch"]["image_limit"], int) and self.config["batch"]["image_limit"] > 0, "å›¾é›†æ‰¹é‡å‘é€é™åˆ¶é…ç½®é”™è¯¯"
            assert isinstance(self.config["batch"]["delay_seconds"], (int, float)) and self.config["batch"]["delay_seconds"] >= 0, "æ‰¹æ¬¡å»¶è¿Ÿæ—¶é—´é…ç½®é”™è¯¯"
            logger.info("[MediaParser] é…ç½®æ–‡ä»¶éªŒè¯é€šè¿‡")
        except AssertionError as e:
            logger.error(f"[MediaParser] é…ç½®æ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
            self.config = self.default_config  # å›é€€åˆ°é»˜è®¤é…ç½®

    def _merge_config(self, default, custom):
        """é€’å½’åˆå¹¶é…ç½®"""
        result = default.copy()
        for key, value in custom.items():
            if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                result[key] = self._merge_config(result[key], value)
            else:
                result[key] = value
        return result

    def _init_cache(self):
        """åˆå§‹åŒ–ç¼“å­˜ç›®å½•"""
        curdir = os.path.dirname(__file__)
        self.cache_dir = os.path.join(curdir, "cache")
        if not os.path.exists(self.cache_dir):
            os.makedirs(self.cache_dir)
        
        # å¯åŠ¨æ—¶æ¸…ç†è¿‡æœŸç¼“å­˜ï¼Œä½¿ç”¨åå°çº¿ç¨‹
        threading.Thread(target=self._clear_expired_cache, daemon=True).start()

    def get_help_text(self, **kwargs):
        help_text = "è§†é¢‘/å›¾é›†è§£ææ’ä»¶ä½¿ç”¨è¯´æ˜ï¼š\n"
        help_text += "1. å‘é€ 'è§£æè§†é¢‘ <é“¾æ¥>' è·å–æ— æ°´å°è§†é¢‘\n"
        help_text += "2. å‘é€ 'è§£æå›¾é›† <é“¾æ¥>' è·å–å›¾é›†åŸå›¾\n"
        help_text += "3. å‘é€ 'æ¸…ç†ç¼“å­˜' æ¸…é™¤ä¸´æ—¶æ–‡ä»¶\n"
        help_text += "4. å‘é€ 'æŸ¥çœ‹ç¼“å­˜' æŸ¥çœ‹ç¼“å­˜çŠ¶æ€\n"
        help_text += "\næ”¯æŒæ‰¹é‡å‘é€å›¾ç‰‡ï¼Œæ¯æ‰¹æœ€å¤šå‘é€ {} å¼ \n".format(
            self.config["batch"]["image_limit"])
        if self.supported_platforms:
            help_text += "\næ”¯æŒçš„å¹³å°ï¼š\n"
            help_text += "ã€".join(self.supported_platforms)
        return help_text

    def on_handle_context(self, e_context: EventContext):
        if e_context['context'].type != ContextType.TEXT:
            return

        content = e_context['context'].content.strip()
        
        if content == "æ¸…ç†ç¼“å­˜":
            result = self.clean_cache()
            e_context['reply'] = Reply(ReplyType.TEXT, result)
            e_context.action = EventAction.BREAK_PASS
            return
            
        elif content == "æŸ¥çœ‹ç¼“å­˜":
            result = self.cache_status()
            e_context['reply'] = Reply(ReplyType.TEXT, result)
            e_context.action = EventAction.BREAK_PASS
            return

        # æ£€æŸ¥æ˜¯å¦æ˜¯è§£æå‘½ä»¤
        if content.startswith(("è§£æè§†é¢‘", "è§£æå›¾é›†")):
            command = "è§£æè§†é¢‘" if content.startswith("è§£æè§†é¢‘") else "è§£æå›¾é›†"
            url = content[len(command):].strip()
            
            if not url:
                e_context['reply'] = Reply(ReplyType.TEXT, f"è¯·æä¾›è¦è§£æçš„é“¾æ¥\nä¾‹å¦‚ï¼š{command} <é“¾æ¥>")
                e_context.action = EventAction.BREAK_PASS
                return

            # è·å–æ¥æ”¶è€…ä¿¡æ¯
            receiver = e_context['context'].kwargs.get('receiver')
            if not receiver:
                e_context['reply'] = Reply(ReplyType.TEXT, "æ— æ³•è·å–æ¥æ”¶è€…ä¿¡æ¯")
                e_context.action = EventAction.BREAK_PASS
                return
            
            try:
                if command == "è§£æè§†é¢‘":
                    reply = self.parse_video(url)
                else:
                    # å°†æ¥æ”¶è€…ä¿¡æ¯å­˜å‚¨åœ¨ä»»åŠ¡ä¸­
                    task_id = f"{receiver}_{int(time.time())}"
                    reply = self.parse_images(url, task_id)
                
                # ç¡®ä¿å›å¤è¢«æ­£ç¡®å‘é€
                if isinstance(reply, list):
                    # æ‰¹é‡å‘é€çš„æƒ…å†µ
                    if reply:
                        # é€ä¸ªå‘é€å›å¤
                        for r in reply:
                            logger.info(f"[MediaParser] å‡†å¤‡å‘é€æ‰¹é‡å›å¤: {r}")
                            self.send_to_channel(r, receiver)
                else:
                    # å•ä¸ªå›å¤çš„æƒ…å†µ
                    logger.info(f"[MediaParser] å‡†å¤‡å‘é€å•ä¸ªå›å¤: {reply}")
                    self.send_to_channel(reply, receiver)
                
                # è®¾ç½®ä¸€ä¸ªç©ºå›å¤ï¼Œé˜²æ­¢é‡å¤å‘é€
                e_context['reply'] = Reply(ReplyType.TEXT, "åª’ä½“è§£æå®Œæˆ")
            except Exception as e:
                logger.error(f"[MediaParser] è§£æå¤±è´¥: {e}", exc_info=True)
                e_context['reply'] = Reply(ReplyType.TEXT, "è§£æå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•")

            e_context.action = EventAction.BREAK_PASS
            return

    def parse_video(self, url):
        """è§£æè§†é¢‘é“¾æ¥"""
        try:
            # ä½¿ç”¨æ–°çš„èšåˆè§£æAPI
            video_api = "https://www.hhlqilongzhu.cn/api/sp_jx/sp.php"
            params = {"url": url}
            
            response = self._make_request("GET", video_api, params=params)
            
            if not response or response.status_code != 200:
                msg = f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}" if response else "APIæ— å“åº”"
                logger.error(f"[MediaParser] è§†é¢‘è§£æAPIè¯·æ±‚å¤±è´¥: {msg}")
                return Reply(ReplyType.TEXT, msg)
            
            # è§£æå“åº”å†…å®¹
            data = response.json()
            if data.get("code") != 200:
                error_msg = data.get("msg", "è§†é¢‘è§£æå¤±è´¥")
                logger.error(f"[MediaParser] è§†é¢‘è§£æå¤±è´¥: {error_msg}")
                return Reply(ReplyType.TEXT, error_msg)
            
            video_data = data.get("data", {})
            if not video_data:
                logger.error("[MediaParser] æœªè·å–åˆ°è§†é¢‘ä¿¡æ¯")
                return Reply(ReplyType.TEXT, "æœªè·å–åˆ°è§†é¢‘ä¿¡æ¯")

            video_url = video_data.get("url")
            if not video_url:
                logger.error("[MediaParser] æœªæ‰¾åˆ°è§†é¢‘åœ°å€")
                return Reply(ReplyType.TEXT, "æœªæ‰¾åˆ°è§†é¢‘åœ°å€")
            
            self._check_cache_size()
            file_obj, filename = self.download_media(video_url, "video")
            if not file_obj:
                logger.error("[MediaParser] è§†é¢‘ä¸‹è½½å¤±è´¥")
                return Reply(ReplyType.TEXT, "è§†é¢‘ä¸‹è½½å¤±è´¥")
            
            # æ„å»ºè¯¦ç»†çš„è§†é¢‘æè¿°
            description_parts = []
            
            # æ·»åŠ æ ‡é¢˜
            if video_data.get("title"):
                description_parts.append(f"ğŸ¬ æ ‡é¢˜ï¼š{video_data['title']}")
            
            # æ·»åŠ ä½œè€…ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            if video_data.get("author"):
                description_parts.append(f"ğŸ‘¤ ä½œè€…ï¼š{video_data['author']}")
            
            # æ·»åŠ æ–‡æœ¬ä¿¡æ¯
            text_info = data.get("text", {})
            if text_info:
                description_parts.append(f"ğŸ“ ä¿¡æ¯ï¼š{text_info.get('msg', '')}")
                description_parts.append(f"ğŸ•’ æ—¶é—´ï¼š{text_info.get('time', '')}")
            
            # ç»„åˆæè¿°
            description = "\n".join(description_parts)
            
            # åˆ›å»ºå›å¤
            reply = Reply(ReplyType.VIDEO, file_obj)
            reply.filename = filename  # è®¾ç½®æ–‡ä»¶å
            reply.text = description if description_parts else "è§†é¢‘å·²æˆåŠŸä¸‹è½½"
            
            logger.info(f"[MediaParser] è§†é¢‘è§£ææˆåŠŸï¼Œæè¿°ï¼š{reply.text}")
            
            return reply
        
        except Exception as e:
            logger.error(f"[MediaParser] è§†é¢‘è§£æå‡ºé”™: {e}", exc_info=True)
            return Reply(ReplyType.TEXT, "è§†é¢‘è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥é“¾æ¥æ˜¯å¦æœ‰æ•ˆ")

    def parse_images(self, url, task_id):
        """è§£æå›¾é›†é“¾æ¥"""
        try:
            # ä½¿ç”¨æ–°çš„èšåˆè§£æå›¾é›†API
            images_api = "https://www.hhlqilongzhu.cn/api/sp_jx/tuji.php"
            params = {"url": url}
            
            response = self._make_request("GET", images_api, params=params)
            
            if not response or response.status_code != 200:
                msg = f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}" if response else "APIæ— å“åº”"
                return Reply(ReplyType.TEXT, msg)
            
            # è§£æå“åº”å†…å®¹
            data = response.json()
            if data.get("code") != 200:
                return Reply(ReplyType.TEXT, data.get("msg", "å›¾é›†è§£æå¤±è´¥"))
            
            image_data = data.get("data", {})
            images = image_data.get("images", [])
            
            if not images:
                return Reply(ReplyType.TEXT, "æœªæ‰¾åˆ°å›¾ç‰‡")
            
            # è®°å½•å›¾ç‰‡æ•°é‡
            logger.info(f"[MediaParser] è·å–åˆ° {len(images)} å¼ å›¾ç‰‡çš„URL")
            
            # å‡†å¤‡å‘é€çš„å›¾ç‰‡åˆ—è¡¨
            image_replies = []
            
            # æ„å»ºè¯¦ç»†çš„å›¾é›†æè¿°
            description_parts = []
            
            # æ·»åŠ ä½œè€…
            if image_data.get("author"):
                description_parts.append(f"ğŸ‘¤ ä½œè€…ï¼š{image_data['author']}")
            
            # æ·»åŠ æ ‡é¢˜
            if image_data.get("title"):
                description_parts.append(f"ğŸ–¼ï¸ æ ‡é¢˜ï¼š{image_data['title']}")
            
            # æ·»åŠ æ–‡æœ¬ä¿¡æ¯
            text_info = image_data.get("text", {})
            if text_info:
                description_parts.append(f"ğŸ“ ä¿¡æ¯ï¼š{text_info.get('msg', '')}")
                description_parts.append(f"ğŸ•’ æ—¶é—´ï¼š{text_info.get('time', '')}")
            
            # ç»„åˆæè¿°
            description = "\n".join(description_parts)
            
            # å‘é€æè¿°æ–‡æœ¬
            if description_parts:
                text_reply = Reply(ReplyType.TEXT, description)
                text_reply.receiver = task_id
                image_replies.append(text_reply)
            
            # ä¸‹è½½å¹¶å‘é€å›¾ç‰‡
            for index, img_url in enumerate(images, 1):
                self._check_cache_size()
                file_obj, filename = self.download_media(img_url, "image")
                
                if file_obj:
                    # ä¸ºæ¯å¼ å›¾ç‰‡åˆ›å»ºå•ç‹¬çš„å›¾ç‰‡æè¿°
                    image_description = f"ğŸ“¸ å›¾ç‰‡ {index}/{len(images)}"
                    
                    # åˆ›å»ºæ–‡æœ¬å›å¤
                    text_reply = Reply(ReplyType.TEXT, image_description)
                    text_reply.receiver = task_id
                    
                    # åˆ›å»ºå›¾ç‰‡å›å¤
                    image_reply = Reply(ReplyType.IMAGE, file_obj)
                    image_reply.filename = filename
                    image_reply.receiver = task_id
                    
                    # åˆ†åˆ«å‘é€æ–‡æœ¬å’Œå›¾ç‰‡
                    image_replies.extend([text_reply, image_reply])
            
            # å‘é€å®Œæˆæç¤º
            complete_reply = Reply(ReplyType.TEXT, f"å›¾é›†å‘é€å®Œæˆï¼Œå…± {len(images)} å¼ å›¾ç‰‡")
            complete_reply.receiver = task_id
            image_replies.append(complete_reply)
            
            return image_replies
        
        except Exception as e:
            logger.error(f"[MediaParser] å›¾é›†è§£æå‡ºé”™: {e}")
            return Reply(ReplyType.TEXT, "å›¾é›†è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥é“¾æ¥æ˜¯å¦æœ‰æ•ˆ")

    def _make_request(self, method, url, **kwargs):
        """å‘é€HTTPè¯·æ±‚ï¼Œæ”¯æŒé‡è¯•æœºåˆ¶"""
        timeout = self.config["download"]["timeout"]
        max_retries = self.config["download"]["max_retries"]
        retry_delay = self.config["download"]["retry_delay"]
        
        for i in range(max_retries + 1):
            try:
                logger.debug(f"[MediaParser] å‘èµ·è¯·æ±‚: method={method}, url={url}, kwargs={kwargs}")
                
                # ä½¿ç”¨ä¼šè¯å‘é€è¯·æ±‚
                response = self.session.request(
                    method, 
                    url, 
                    timeout=timeout, 
                    **kwargs
                )
                
                # è®°å½•å®Œæ•´çš„å“åº”ä¿¡æ¯
                logger.debug(f"[MediaParser] å“åº”çŠ¶æ€ç : {response.status_code}")
                logger.debug(f"[MediaParser] å“åº”å¤´: {dict(response.headers)}")
                
                # å¦‚æœæ˜¯ JSON è¯·æ±‚ï¼Œè®°å½• JSON å†…å®¹
                try:
                    json_data = response.json()
                    logger.debug(f"[MediaParser] å“åº” JSON: {json_data}")
                except Exception as json_error:
                    logger.debug(f"[MediaParser] è§£æ JSON å¤±è´¥: {json_error}")
                
                # æ£€æŸ¥å“åº”çŠ¶æ€ç 
                if response.status_code == 200:
                    return response
                
                logger.warning(f"[MediaParser] è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                
            except requests.exceptions.RequestException as e:
                logger.warning(f"[MediaParser] è¯·æ±‚å¤±è´¥ï¼Œå°†åœ¨ {retry_delay} ç§’åé‡è¯•ï¼ˆç¬¬ {i+1} æ¬¡ï¼‰: {e}")
                
                if i == max_retries:
                    logger.error(f"[MediaParser] è¯·æ±‚æœ€ç»ˆå¤±è´¥: {e}")
                    return None
                
                time.sleep(retry_delay)
            
            except Exception as e:
                logger.error(f"[MediaParser] æœªçŸ¥é”™è¯¯: {e}")
                return None

    def download_media(self, url, media_type):
        """ä¸‹è½½åª’ä½“æ–‡ä»¶ï¼Œå¹¶è¿”å›æ–‡ä»¶å¯¹è±¡å’Œæ–‡ä»¶å"""
        try:
            # å‘èµ·è¯·æ±‚ï¼Œè·å–å“åº”
            response = self._make_request("GET", url, stream=True)
            
            if response is None:
                logger.error(f"[MediaParser] ä¸‹è½½å¤±è´¥ï¼šæ— æ³•è·å–å“åº” (URL: {url})")
                return None, None
            
            # æ£€æŸ¥å†…å®¹ç±»å‹
            content_type = response.headers.get('Content-Type', '').lower()
            logger.debug(f"[MediaParser] å†…å®¹ç±»å‹: {content_type}")
            
            # éªŒè¯åª’ä½“ç±»å‹
            if media_type == "video":
                ext = self.video_extensions.get(content_type, '.mp4')
                mime_type = content_type or 'video/mp4'
                if "video" not in content_type:
                    logger.warning(f"[MediaParser] ä¸æ˜¯è§†é¢‘å†…å®¹: {content_type}")
            else:
                ext = self.image_extensions.get(content_type, '.jpg')
                mime_type = content_type or 'image/jpeg'
                if "image" not in content_type:
                    logger.warning(f"[MediaParser] ä¸æ˜¯å›¾ç‰‡å†…å®¹: {content_type}")
            
            # ä½¿ç”¨URLçš„MD5ä½œä¸ºæ–‡ä»¶å
            url_hash = hashlib.md5(url.encode()).hexdigest()
            filename = f"{int(time.time())}_{url_hash}"
            
            # ä¸‹è½½æ–‡ä»¶å†…å®¹åˆ°å†…å­˜
            file_content = response.content
            
            # è®°å½•æ–‡ä»¶å¤§å°å’Œç±»å‹
            logger.debug(f"[MediaParser] æ–‡ä»¶å¤§å°: {len(file_content)} å­—èŠ‚")
            logger.debug(f"[MediaParser] æ–‡ä»¶æ‰©å±•å: {ext}")
            
            # å¦‚æœæ˜¯ WebP æ ¼å¼ï¼Œè½¬æ¢ä¸º PNG
            if ext == '.webp':
                try:
                    from PIL import Image
                    import io
                    
                    # ä½¿ç”¨ Pillow è½¬æ¢ WebP åˆ° PNG
                    with Image.open(io.BytesIO(file_content)) as img:
                        png_buffer = io.BytesIO()
                        img.save(png_buffer, format='PNG')
                        file_content = png_buffer.getvalue()
                    
                    ext = '.png'
                    logger.info("[MediaParser] æˆåŠŸå°† WebP è½¬æ¢ä¸º PNG")
                except ImportError:
                    logger.warning("[MediaParser] Pillow æœªå®‰è£…ï¼Œæ— æ³•è½¬æ¢ WebP")
                except Exception as convert_error:
                    logger.error(f"[MediaParser] WebP è½¬æ¢å¤±è´¥: {convert_error}")
            
            # å®Œæ•´æ–‡ä»¶å
            full_filename = filename + ext
            
            # åˆ›å»ºä¸€ä¸ªæ–°çš„ BytesIO å¯¹è±¡ç”¨äºå‘é€
            file_obj = BytesIO(file_content)
            
            # è®¾ç½®æ–‡ä»¶å¯¹è±¡çš„å±æ€§
            file_obj.name = full_filename
            
            # ä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿä½œä¸ºç¼“å­˜
            filepath = os.path.join(self.cache_dir, full_filename)
            with open(filepath, 'wb') as f:
                f.write(file_content)
            
            # ä¿å­˜æ–‡ä»¶è·¯å¾„ä»¥ä¾¿åç»­æ¸…ç†
            setattr(file_obj, '_filepath', filepath)
            
            # è®°å½•æ–‡ä»¶è¯¦ç»†ä¿¡æ¯
            logger.info(f"[MediaParser] æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {full_filename}")
            logger.info(f"[MediaParser] æ–‡ä»¶è·¯å¾„: {filepath}")
            logger.info(f"[MediaParser] MIMEç±»å‹: {mime_type}")
            
            return file_obj, full_filename
                
        except Exception as e:
            logger.error(f"[MediaParser] ä¸‹è½½å¤±è´¥: {e}")
            logger.exception("è¯¦ç»†é”™è¯¯è¿½è¸ª:")
            return None, None

    def close_file(self, file_obj):
        """å®‰å…¨åœ°å…³é—­æ–‡ä»¶å¯¹è±¡"""
        try:
            if hasattr(file_obj, '_filepath'):
                filepath = getattr(file_obj, '_filepath')
                if os.path.exists(filepath):
                    try:
                        os.remove(filepath)
                        logger.debug(f"[MediaParser] åˆ é™¤ç¼“å­˜æ–‡ä»¶: {filepath}")
                    except Exception as e:
                        logger.warning(f"[MediaParser] åˆ é™¤ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")
            if hasattr(file_obj, 'close'):
                file_obj.close()
        except Exception as e:
            logger.error(f"[MediaParser] å…³é—­æ–‡ä»¶å¤±è´¥: {e}")

    def _clear_expired_cache(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        try:
            # æ£€æŸ¥ç¼“å­˜ç›®å½•æ˜¯å¦å­˜åœ¨
            if not hasattr(self, 'cache_dir') or not os.path.exists(self.cache_dir):
                logger.warning("[MediaParser] ç¼“å­˜ç›®å½•ä¸å­˜åœ¨")
                return
            
            # æ£€æŸ¥ç¼“å­˜é”æ˜¯å¦å­˜åœ¨
            if not hasattr(self, 'cache_lock'):
                logger.warning("[MediaParser] ç¼“å­˜é”æœªåˆå§‹åŒ–ï¼Œåˆ›å»ºæ–°çš„é”")
                self.cache_lock = threading.Lock()
            
            max_age = self.config["cache"]["max_age_hours"] * 3600
            now = time.time()
            
            with self.cache_lock:
                for f in os.listdir(self.cache_dir):
                    filepath = os.path.join(self.cache_dir, f)
                    try:
                        if os.path.isfile(filepath):
                            file_age = now - os.path.getctime(filepath)
                            if file_age > max_age:
                                try:
                                    os.remove(filepath)
                                    logger.debug(f"[MediaParser] åˆ é™¤è¿‡æœŸæ–‡ä»¶: {f}")
                                except OSError as remove_error:
                                    logger.error(f"[MediaParser] åˆ é™¤æ–‡ä»¶å¤±è´¥: {remove_error}")
                    except Exception as file_error:
                        logger.error(f"[MediaParser] å¤„ç†æ–‡ä»¶ {f} æ—¶å‡ºé”™: {file_error}")
                            
        except Exception as e:
            logger.error(f"[MediaParser] æ¸…ç†è¿‡æœŸç¼“å­˜å¤±è´¥: {e}")
            # å°è¯•é‡æ–°åˆå§‹åŒ–ç¼“å­˜é”
            self.cache_lock = threading.Lock()

    def _check_cache_size(self):
        """æ£€æŸ¥å¹¶æ§åˆ¶ç¼“å­˜å¤§å°"""
        try:
            max_size = self.config["cache"]["max_size_mb"] * 1024 * 1024
            with self.cache_lock:
                files = []
                total_size = 0
                for f in os.listdir(self.cache_dir):
                    filepath = os.path.join(self.cache_dir, f)
                    if os.path.isfile(filepath):
                        size = os.path.getsize(filepath)
                        ctime = os.path.getctime(filepath)
                        files.append((filepath, size, ctime))
                        total_size += size
                        
                if total_size > max_size:
                    # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼Œåˆ é™¤æœ€è€çš„æ–‡ä»¶
                    files.sort(key=lambda x: x[2])
                    
                    for filepath, size, _ in files:
                        try:
                            os.remove(filepath)
                            total_size -= size
                            logger.debug(f"[MediaParser] åˆ é™¤ç¼“å­˜æ–‡ä»¶: {os.path.basename(filepath)}")
                            if total_size <= max_size:
                                break
                        except OSError as e:
                            logger.error(f"[MediaParser] åˆ é™¤æ–‡ä»¶å¤±è´¥: {e}")
                            
        except Exception as e:
            logger.error(f"[MediaParser] æ£€æŸ¥ç¼“å­˜å¤§å°å¤±è´¥: {e}")

    def clean_cache(self):
        """æ¸…ç†æ‰€æœ‰ç¼“å­˜"""
        try:
            with self.cache_lock:
                files = [f for f in os.listdir(self.cache_dir) 
                        if os.path.isfile(os.path.join(self.cache_dir, f))]
                total_size = sum(os.path.getsize(os.path.join(self.cache_dir, f)) 
                               for f in files)
                
                for f in files:
                    try:
                        os.remove(os.path.join(self.cache_dir, f))
                    except OSError as e:
                        logger.error(f"[MediaParser] åˆ é™¤æ–‡ä»¶å¤±è´¥: {e}")
                        
            return f"ç¼“å­˜å·²æ¸…ç†\næ¸…ç†å‰ï¼š{len(files)}ä¸ªæ–‡ä»¶ï¼Œ{self.format_size(total_size)}"
                
        except Exception as e:
            logger.error(f"[MediaParser] æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
            return "æ¸…ç†ç¼“å­˜å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"

    def cache_status(self):
        """è·å–ç¼“å­˜çŠ¶æ€"""
        try:
            with self.cache_lock:
                files = [f for f in os.listdir(self.cache_dir) 
                        if os.path.isfile(os.path.join(self.cache_dir, f))]
                total_size = sum(os.path.getsize(os.path.join(self.cache_dir, f)) 
                               for f in files)
                
                max_size = self.config["cache"]["max_size_mb"]
                max_age = self.config["cache"]["max_age_hours"]
                
                status = f"ç¼“å­˜çŠ¶æ€ï¼š\n"
                status += f"æ–‡ä»¶æ•°ï¼š{len(files)}\n"
                status += f"å ç”¨ç©ºé—´ï¼š{self.format_size(total_size)}\n"
                status += f"æœ€å¤§ç©ºé—´ï¼š{max_size}MB\n"
                status += f"è¿‡æœŸæ—¶é—´ï¼š{max_age}å°æ—¶"
                
                return status
                
        except Exception as e:
            logger.error(f"[MediaParser] è·å–ç¼“å­˜çŠ¶æ€å¤±è´¥: {e}")
            return "è·å–ç¼“å­˜çŠ¶æ€å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"

    def format_size(self, size):
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        units = ['B', 'KB', 'MB', 'GB']
        unit_index = 0
        while size >= 1024 and unit_index < len(units) - 1:
            size /= 1024
            unit_index += 1
        return f"{size:.2f} {units[unit_index]}"

    def _process_pending_tasks(self):
        """åå°çº¿ç¨‹å¤„ç†å¾…å‘é€çš„ä»»åŠ¡"""
        while not self.stop_event.is_set():
            try:
                current_time = time.time()
                tasks_to_remove = []
                
                with self.tasks_lock:
                    for task_id, task in self.processing_tasks.items():
                        if current_time >= task['next_send_time']:
                            # è·å–ä¸‹ä¸€ä¸ªè¦å‘é€çš„å›å¤
                            reply = task['replies'][task['index']]
                            receiver = task['receiver']  # ä»ä»»åŠ¡ä¸­è·å–æ¥æ”¶è€…ä¿¡æ¯
                            
                            try:
                                # å‘é€å›å¤
                                self.send_to_channel(reply, receiver)
                                logger.debug(f"[MediaParser] å‘é€æˆåŠŸ: {reply}")
                                
                                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                                task['index'] += 1
                                if task['index'] >= len(task['replies']):
                                    # æ‰€æœ‰å›å¤éƒ½å·²å‘é€å®Œæˆ
                                    tasks_to_remove.append(task_id)
                                    logger.info(f"[MediaParser] ä»»åŠ¡å®Œæˆ: {task_id}")
                                else:
                                    # è®¾ç½®ä¸‹ä¸€æ¬¡å‘é€æ—¶é—´
                                    task['next_send_time'] = current_time + self.config["batch"]["delay_seconds"]
                                    
                            except Exception as e:
                                logger.error(f"[MediaParser] å‘é€å¤±è´¥: {e}")
                                # å‘é€å¤±è´¥æ—¶ä¹Ÿç§»é™¤ä»»åŠ¡
                                tasks_to_remove.append(task_id)
                    
                    # æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡
                    for task_id in tasks_to_remove:
                        task = self.processing_tasks.pop(task_id)
                        # æ¸…ç†ç›¸å…³çš„æ–‡ä»¶å¯¹è±¡
                        if 'replies' in task:
                            self.clean_up_files(task['replies'])
                
            except Exception as e:
                logger.error(f"[MediaParser] å¤„ç†ä»»åŠ¡å‡ºé”™: {e}")
            
            # çŸ­æš‚ä¼‘çœ ä»¥é¿å…è¿‡åº¦å ç”¨CPU
            time.sleep(0.1)

    def send_reply(self, reply):
        """å‘é€Replyå¯¹è±¡çš„è¾…åŠ©æ–¹æ³•"""
        try:
            # å‡è®¾ context ä¸­åŒ…å« receiver ä¿¡æ¯
            receiver = reply.receiver  # ç¡®ä¿ Reply å¯¹è±¡åŒ…å« receiver å±æ€§
            logger.debug(f"[MediaParser] å‘é€Replyç±»å‹: {reply.type}, å†…å®¹: {reply.content}")
            self.send_to_channel(reply, receiver)
            # å‘é€å®Œæˆåå…³é—­æ–‡ä»¶å¯¹è±¡
            self.clean_up_files([reply])
        except Exception as e:
            logger.error(f"[MediaParser] å‘é€Replyå¤±è´¥: {e}")

    def send_to_channel(self, reply, receiver):
        """å‘é€Replyå¯¹è±¡åˆ°ç›®æ ‡é¢‘é“"""
        try:
            from channel.channel_factory import create_channel
            from bridge.context import Context
            from bridge.reply import ReplyType
            
            # è®°å½•å‘é€å‰çš„è¯¦ç»†ä¿¡æ¯
            logger.info(f"[MediaParser] å‡†å¤‡å‘é€Reply: ç±»å‹={reply.type}, æ¥æ”¶è€…={receiver}")
            
            channel = create_channel("wx")
            if channel:
                # åˆ›å»º Context å¯¹è±¡ï¼Œè®¾ç½®å¿…è¦çš„å‚æ•°
                context = Context()
                context.kwargs = {'receiver': receiver}
                
                # å¦‚æœæ˜¯å›¾ç‰‡æˆ–è§†é¢‘ç±»å‹ï¼Œå…ˆå‘é€æ–‡æœ¬æè¿°
                if reply.type in [ReplyType.IMAGE, ReplyType.VIDEO]:
                    # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„æ–‡æœ¬æè¿°
                    description = getattr(reply, 'text', None)
                    
                    if description and isinstance(description, str):
                        # å…ˆå‘é€æ–‡æœ¬æè¿°
                        text_reply = Reply(ReplyType.TEXT, description)
                        text_reply.receiver = receiver
                        channel.send(text_reply, context)
                        logger.info(f"[MediaParser] å‘é€åª’ä½“æè¿°æ–‡æœ¬: {description}")
                
                # å‘é€åª’ä½“æ–‡ä»¶
                try:
                    channel.send(reply, context)
                    logger.info(f"[MediaParser] é€šè¿‡channelå‘é€åª’ä½“æ–‡ä»¶æˆåŠŸ: {reply}")
                except Exception as send_error:
                    logger.error(f"[MediaParser] channelå‘é€åª’ä½“æ–‡ä»¶å¤±è´¥: {send_error}")
                    # å°è¯•æ‰“å°æ›´å¤šè¯Šæ–­ä¿¡æ¯
                    import traceback
                    logger.error(f"[MediaParser] å‘é€åª’ä½“æ–‡ä»¶é”™è¯¯è¿½è¸ª: {traceback.format_exc()}")
                    raise
            else:
                logger.error("[MediaParser] æœªæ‰¾åˆ°å¾®ä¿¡channel")
                raise RuntimeError("æœªæ‰¾åˆ°å¾®ä¿¡channel")
        
        except Exception as e:
            logger.error(f"[MediaParser] å‘é€åˆ°channelå¤±è´¥: {e}")
            import traceback
            logger.error(f"[MediaParser] è¯¦ç»†é”™è¯¯è¿½è¸ª: {traceback.format_exc()}")
            raise

    def clean_up_files(self, reply_list):
        """åœ¨æ‰€æœ‰å›å¤å‘é€å®Œæˆåå…³é—­æ–‡ä»¶å¯¹è±¡"""
        for reply in reply_list:
            if reply.type in [ReplyType.IMAGE, ReplyType.VIDEO]:
                try:
                    self.close_file(reply.content)
                except Exception as e:
                    logger.error(f"[MediaParser] å…³é—­æ–‡ä»¶å¤±è´¥: {e}")

    def __del__(self):
        """æ¸…ç†èµ„æº"""
        try:
            self.stop_event.set()
            self.worker_thread.join(timeout=5)
            self.session.close()
            self.executor.shutdown(wait=False)
        except Exception as e:
            logger.error(f"[MediaParser] å…³é—­èµ„æºå¤±è´¥: {e}")

import re
import requests
import time
import os
import json
from bridge.reply import Reply, ReplyType
from bridge.context import ContextType, Context
from common.log import logger
from plugins import register, Plugin, Event, EventContext, EventAction
from concurrent.futures import ThreadPoolExecutor
from functools import partial
import hashlib
import threading
from io import BytesIO
from PIL import Image
import io

@register(name="media_parser", desc="è§†é¢‘å›¾é›†è§£ææ’ä»¶", version="1.4", author="å®‰ä¸", desire_priority=100)
class MediaParserPlugin(Plugin):
    def __init__(self):
        super().__init__()
        self.handlers[Event.ON_HANDLE_CONTEXT] = self.on_handle_context
        
        # åˆå§‹åŒ–é…ç½®å’Œç¼“å­˜
        self._load_config()
        self._init_cache()
        
        # åˆå§‹åŒ–ä¼šè¯å’Œçº¿ç¨‹æ± 
        self.session = requests.Session()
        self.executor = ThreadPoolExecutor(max_workers=5)  # å¢åŠ çº¿ç¨‹æ± å¤§å°ä»¥æé«˜ä¸‹è½½æ•ˆç‡
        
        # çº¿ç¨‹é”ç”¨äºç¼“å­˜ç®¡ç†çš„åŒæ­¥
        self.cache_lock = threading.Lock()  # ç¡®ä¿è¿™è¡Œå­˜åœ¨
        self.tasks_lock = threading.Lock()
        
        # æ”¯æŒçš„æ–‡ä»¶ç±»å‹
        self.video_extensions = {
            'video/mp4': '.mp4',
            'video/x-flv': '.flv',
            'video/quicktime': '.mov',
            'video/x-ms-wmv': '.wmv',
            'video/x-msvideo': '.avi',
        }
        
        self.image_extensions = {
            'image/jpeg': '.jpg',
            'image/png': '.png',
            'image/gif': '.gif',
            'image/webp': '.webp',
            'image/bmp': '.bmp',
        }
        
        # è®°å½•æ­£åœ¨å¤„ç†çš„ä»»åŠ¡
        self.processing_tasks = {}
        
        # å¯åŠ¨åå°çº¿ç¨‹å¤„ç†å¾…å‘é€çš„ä»»åŠ¡
        self.stop_event = threading.Event()
        self.worker_thread = threading.Thread(target=self._process_pending_tasks, daemon=True)
        self.worker_thread.start()
        
        logger.info("[MediaParser] æ’ä»¶å·²åŠ è½½")

    def _load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        curdir = os.path.dirname(__file__)
        config_path = os.path.join(curdir, "config.json")
        
        self.default_config = {
            "api_endpoints": {
                "video": "https://www.hhlqilongzhu.cn/api/sp_jx/sp.php",
                "image": "https://www.hhlqilongzhu.cn/api/sp_jx/tuji.php"
            },
            "supported_platforms": [
                "æŠ–éŸ³",
                "å¿«æ‰‹",
                "å¾®åš",
                "å°çº¢ä¹¦"
            ],
            "cache": {
                "max_size_mb": 500,
                "max_age_hours": 24,
                "chunk_size": 8192
            },
            "download": {
                "timeout": 30,
                "max_retries": 3,
                "retry_delay": 1,
                "max_workers": 5
            },
            "batch": {
                "image_limit": 10,  # æ¯æ‰¹æœ€å¤šå‘é€çš„å›¾ç‰‡æ•°
                "delay_seconds": 2   # æ‰¹æ¬¡é—´å»¶è¿Ÿæ—¶é—´
            }
        }
        
        try:
            if os.path.exists(config_path):
                with open(config_path, "r", encoding="utf-8") as f:
                    config = json.load(f)
                self.config = self._merge_config(self.default_config, config)
            else:
                self.config = self.default_config
                with open(config_path, "w", encoding="utf-8") as f:
                    json.dump(self.config, f, indent=4, ensure_ascii=False)
        except Exception as e:
            logger.warn(f"[MediaParser] åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤é…ç½®")
            self.config = self.default_config
            
        # è®¾ç½®API endpoints
        self.video_api = self.config["api_endpoints"]["video"]
        self.image_api = self.config["api_endpoints"]["image"]
        self.supported_platforms = self.config.get("supported_platforms", [])

        # é…ç½®éªŒè¯
        self._validate_config()

    def _validate_config(self):
        """éªŒè¯é…ç½®æ–‡ä»¶çš„æœ‰æ•ˆæ€§"""
        try:
            assert isinstance(self.config["cache"]["max_size_mb"], (int, float)) and self.config["cache"]["max_size_mb"] > 0, "ç¼“å­˜å¤§å°é…ç½®é”™è¯¯"
            assert isinstance(self.config["cache"]["max_age_hours"], (int, float)) and self.config["cache"]["max_age_hours"] > 0, "ç¼“å­˜è¿‡æœŸæ—¶é—´é…ç½®é”™è¯¯"
            assert isinstance(self.config["download"]["timeout"], (int, float)) and self.config["download"]["timeout"] > 0, "ä¸‹è½½è¶…æ—¶é…ç½®é”™è¯¯"
            assert isinstance(self.config["download"]["max_retries"], int) and self.config["download"]["max_retries"] >= 0, "æœ€å¤§é‡è¯•æ¬¡æ•°é…ç½®é”™è¯¯"
            assert isinstance(self.config["download"]["retry_delay"], (int, float)) and self.config["download"]["retry_delay"] >= 0, "é‡è¯•å»¶è¿Ÿé…ç½®é”™è¯¯"
            assert isinstance(self.config["batch"]["image_limit"], int) and self.config["batch"]["image_limit"] > 0, "å›¾é›†æ‰¹é‡å‘é€é™åˆ¶é…ç½®é”™è¯¯"
            assert isinstance(self.config["batch"]["delay_seconds"], (int, float)) and self.config["batch"]["delay_seconds"] >= 0, "æ‰¹æ¬¡å»¶è¿Ÿæ—¶é—´é…ç½®é”™è¯¯"
            logger.info("[MediaParser] é…ç½®æ–‡ä»¶éªŒè¯é€šè¿‡")
        except AssertionError as e:
            logger.error(f"[MediaParser] é…ç½®æ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
            self.config = self.default_config  # å›é€€åˆ°é»˜è®¤é…ç½®

    def _merge_config(self, default, custom):
        """é€’å½’åˆå¹¶é…ç½®"""
        result = default.copy()
        for key, value in custom.items():
            if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                result[key] = self._merge_config(result[key], value)
            else:
                result[key] = value
        return result

    def _init_cache(self):
        """åˆå§‹åŒ–ç¼“å­˜ç›®å½•"""
        curdir = os.path.dirname(__file__)
        self.cache_dir = os.path.join(curdir, "cache")
        if not os.path.exists(self.cache_dir):
            os.makedirs(self.cache_dir)
        
        # å¯åŠ¨æ—¶æ¸…ç†è¿‡æœŸç¼“å­˜ï¼Œä½¿ç”¨åå°çº¿ç¨‹
        threading.Thread(target=self._clear_expired_cache, daemon=True).start()

    def get_help_text(self, **kwargs):
        help_text = "è§†é¢‘/å›¾é›†è§£ææ’ä»¶ä½¿ç”¨è¯´æ˜ï¼š\n"
        help_text += "1. å‘é€ 'è§£æè§†é¢‘ <é“¾æ¥>' è·å–æ— æ°´å°è§†é¢‘\n"
        help_text += "2. å‘é€ 'è§£æå›¾é›† <é“¾æ¥>' è·å–å›¾é›†åŸå›¾\n"
        help_text += "3. å‘é€ 'æ¸…ç†ç¼“å­˜' æ¸…é™¤ä¸´æ—¶æ–‡ä»¶\n"
        help_text += "4. å‘é€ 'æŸ¥çœ‹ç¼“å­˜' æŸ¥çœ‹ç¼“å­˜çŠ¶æ€\n"
        help_text += "\næ”¯æŒæ‰¹é‡å‘é€å›¾ç‰‡ï¼Œæ¯æ‰¹æœ€å¤šå‘é€ {} å¼ \n".format(
            self.config["batch"]["image_limit"])
        if self.supported_platforms:
            help_text += "\næ”¯æŒçš„å¹³å°ï¼š\n"
            help_text += "ã€".join(self.supported_platforms)
        return help_text

    def on_handle_context(self, e_context: EventContext):
        if e_context['context'].type != ContextType.TEXT:
            return

        content = e_context['context'].content.strip()
        
        if content == "æ¸…ç†ç¼“å­˜":
            result = self.clean_cache()
            e_context['reply'] = Reply(ReplyType.TEXT, result)
            e_context.action = EventAction.BREAK_PASS
            return
            
        elif content == "æŸ¥çœ‹ç¼“å­˜":
            result = self.cache_status()
            e_context['reply'] = Reply(ReplyType.TEXT, result)
            e_context.action = EventAction.BREAK_PASS
            return

        # æ£€æŸ¥æ˜¯å¦æ˜¯è§£æå‘½ä»¤
        if content.startswith(("è§£æè§†é¢‘", "è§£æå›¾é›†")):
            command = "è§£æè§†é¢‘" if content.startswith("è§£æè§†é¢‘") else "è§£æå›¾é›†"
            url = content[len(command):].strip()
            
            if not url:
                e_context['reply'] = Reply(ReplyType.TEXT, f"è¯·æä¾›è¦è§£æçš„é“¾æ¥\nä¾‹å¦‚ï¼š{command} <é“¾æ¥>")
                e_context.action = EventAction.BREAK_PASS
                return

            # è·å–æ¥æ”¶è€…ä¿¡æ¯
            receiver = e_context['context'].kwargs.get('receiver')
            if not receiver:
                e_context['reply'] = Reply(ReplyType.TEXT, "æ— æ³•è·å–æ¥æ”¶è€…ä¿¡æ¯")
                e_context.action = EventAction.BREAK_PASS
                return
            
            try:
                if command == "è§£æè§†é¢‘":
                    reply = self.parse_video(url)
                else:
                    # å°†æ¥æ”¶è€…ä¿¡æ¯å­˜å‚¨åœ¨ä»»åŠ¡ä¸­
                    task_id = f"{receiver}_{int(time.time())}"
                    reply = self.parse_images(url, task_id)
                
                # ç¡®ä¿å›å¤è¢«æ­£ç¡®å‘é€
                if isinstance(reply, list):
                    # æ‰¹é‡å‘é€çš„æƒ…å†µ
                    if reply:
                        # é€ä¸ªå‘é€å›å¤
                        for r in reply:
                            logger.info(f"[MediaParser] å‡†å¤‡å‘é€æ‰¹é‡å›å¤: {r}")
                            self.send_to_channel(r, receiver)
                else:
                    # å•ä¸ªå›å¤çš„æƒ…å†µ
                    logger.info(f"[MediaParser] å‡†å¤‡å‘é€å•ä¸ªå›å¤: {reply}")
                    self.send_to_channel(reply, receiver)
                
                # è®¾ç½®ä¸€ä¸ªç©ºå›å¤ï¼Œé˜²æ­¢é‡å¤å‘é€
                e_context['reply'] = Reply(ReplyType.TEXT, "åª’ä½“è§£æå®Œæˆ")
            except Exception as e:
                logger.error(f"[MediaParser] è§£æå¤±è´¥: {e}", exc_info=True)
                e_context['reply'] = Reply(ReplyType.TEXT, "è§£æå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•")

            e_context.action = EventAction.BREAK_PASS
            return

    def parse_video(self, url):
        """è§£æè§†é¢‘é“¾æ¥"""
        try:
            # ä½¿ç”¨æ–°çš„èšåˆè§£æAPI
            video_api = "https://www.hhlqilongzhu.cn/api/sp_jx/sp.php"
            params = {"url": url}
            
            response = self._make_request("GET", video_api, params=params)
            
            if not response or response.status_code != 200:
                msg = f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}" if response else "APIæ— å“åº”"
                logger.error(f"[MediaParser] è§†é¢‘è§£æAPIè¯·æ±‚å¤±è´¥: {msg}")
                return Reply(ReplyType.TEXT, msg)
            
            # è§£æå“åº”å†…å®¹
            data = response.json()
            if data.get("code") != 200:
                error_msg = data.get("msg", "è§†é¢‘è§£æå¤±è´¥")
                logger.error(f"[MediaParser] è§†é¢‘è§£æå¤±è´¥: {error_msg}")
                return Reply(ReplyType.TEXT, error_msg)
            
            video_data = data.get("data", {})
            if not video_data:
                logger.error("[MediaParser] æœªè·å–åˆ°è§†é¢‘ä¿¡æ¯")
                return Reply(ReplyType.TEXT, "æœªè·å–åˆ°è§†é¢‘ä¿¡æ¯")

            video_url = video_data.get("url")
            if not video_url:
                logger.error("[MediaParser] æœªæ‰¾åˆ°è§†é¢‘åœ°å€")
                return Reply(ReplyType.TEXT, "æœªæ‰¾åˆ°è§†é¢‘åœ°å€")
            
            self._check_cache_size()
            file_obj, filename = self.download_media(video_url, "video")
            if not file_obj:
                logger.error("[MediaParser] è§†é¢‘ä¸‹è½½å¤±è´¥")
                return Reply(ReplyType.TEXT, "è§†é¢‘ä¸‹è½½å¤±è´¥")
            
            # æ„å»ºè¯¦ç»†çš„è§†é¢‘æè¿°
            description_parts = []
            
            # æ·»åŠ æ ‡é¢˜
            if video_data.get("title"):
                description_parts.append(f"ğŸ¬ æ ‡é¢˜ï¼š{video_data['title']}")
            
            # æ·»åŠ ä½œè€…ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            if video_data.get("author"):
                description_parts.append(f"ğŸ‘¤ ä½œè€…ï¼š{video_data['author']}")
            
            # æ·»åŠ æ–‡æœ¬ä¿¡æ¯
            text_info = data.get("text", {})
            if text_info:
                description_parts.append(f"ğŸ“ ä¿¡æ¯ï¼š{text_info.get('msg', '')}")
                description_parts.append(f"ğŸ•’ æ—¶é—´ï¼š{text_info.get('time', '')}")
            
            # ç»„åˆæè¿°
            description = "\n".join(description_parts)
            
            # åˆ›å»ºå›å¤
            reply = Reply(ReplyType.VIDEO, file_obj)
            reply.filename = filename  # è®¾ç½®æ–‡ä»¶å
            reply.text = description if description_parts else "è§†é¢‘å·²æˆåŠŸä¸‹è½½"
            
            logger.info(f"[MediaParser] è§†é¢‘è§£ææˆåŠŸï¼Œæè¿°ï¼š{reply.text}")
            
            return reply
        
        except Exception as e:
            logger.error(f"[MediaParser] è§†é¢‘è§£æå‡ºé”™: {e}", exc_info=True)
            return Reply(ReplyType.TEXT, "è§†é¢‘è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥é“¾æ¥æ˜¯å¦æœ‰æ•ˆ")

    def parse_images(self, url, task_id):
        """è§£æå›¾é›†é“¾æ¥"""
        try:
            # ä½¿ç”¨æ–°çš„èšåˆè§£æå›¾é›†API
            images_api = "https://www.hhlqilongzhu.cn/api/sp_jx/tuji.php"
            params = {"url": url}
            
            response = self._make_request("GET", images_api, params=params)
            
            if not response or response.status_code != 200:
                msg = f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}" if response else "APIæ— å“åº”"
                return Reply(ReplyType.TEXT, msg)
            
            # è§£æå“åº”å†…å®¹
            data = response.json()
            if data.get("code") != 200:
                return Reply(ReplyType.TEXT, data.get("msg", "å›¾é›†è§£æå¤±è´¥"))
            
            image_data = data.get("data", {})
            images = image_data.get("images", [])
            
            if not images:
                return Reply(ReplyType.TEXT, "æœªæ‰¾åˆ°å›¾ç‰‡")
            
            # è®°å½•å›¾ç‰‡æ•°é‡
            logger.info(f"[MediaParser] è·å–åˆ° {len(images)} å¼ å›¾ç‰‡çš„URL")
            
            # å‡†å¤‡å‘é€çš„å›¾ç‰‡åˆ—è¡¨
            image_replies = []
            
            # æ„å»ºè¯¦ç»†çš„å›¾é›†æè¿°
            description_parts = []
            
            # æ·»åŠ ä½œè€…
            if image_data.get("author"):
                description_parts.append(f"ğŸ‘¤ ä½œè€…ï¼š{image_data['author']}")
            
            # æ·»åŠ æ ‡é¢˜
            if image_data.get("title"):
                description_parts.append(f"ğŸ–¼ï¸ æ ‡é¢˜ï¼š{image_data['title']}")
            
            # æ·»åŠ æ–‡æœ¬ä¿¡æ¯
            text_info = image_data.get("text", {})
            if text_info:
                description_parts.append(f"ğŸ“ ä¿¡æ¯ï¼š{text_info.get('msg', '')}")
                description_parts.append(f"ğŸ•’ æ—¶é—´ï¼š{text_info.get('time', '')}")
            
            # ç»„åˆæè¿°
            description = "\n".join(description_parts)
            
            # å‘é€æè¿°æ–‡æœ¬
            if description_parts:
                text_reply = Reply(ReplyType.TEXT, description)
                text_reply.receiver = task_id
                image_replies.append(text_reply)
            
            # ä¸‹è½½å¹¶å‘é€å›¾ç‰‡
            for index, img_url in enumerate(images, 1):
                self._check_cache_size()
                file_obj, filename = self.download_media(img_url, "image")
                
                if file_obj:
                    # ä¸ºæ¯å¼ å›¾ç‰‡åˆ›å»ºå•ç‹¬çš„å›¾ç‰‡æè¿°
                    image_description = f"ğŸ“¸ å›¾ç‰‡ {index}/{len(images)}"
                    
                    # åˆ›å»ºæ–‡æœ¬å›å¤
                    text_reply = Reply(ReplyType.TEXT, image_description)
                    text_reply.receiver = task_id
                    
                    # åˆ›å»ºå›¾ç‰‡å›å¤
                    image_reply = Reply(ReplyType.IMAGE, file_obj)
                    image_reply.filename = filename
                    image_reply.receiver = task_id
                    
                    # åˆ†åˆ«å‘é€æ–‡æœ¬å’Œå›¾ç‰‡
                    image_replies.extend([text_reply, image_reply])
            
            # å‘é€å®Œæˆæç¤º
            complete_reply = Reply(ReplyType.TEXT, f"å›¾é›†å‘é€å®Œæˆï¼Œå…± {len(images)} å¼ å›¾ç‰‡")
            complete_reply.receiver = task_id
            image_replies.append(complete_reply)
            
            return image_replies
        
        except Exception as e:
            logger.error(f"[MediaParser] å›¾é›†è§£æå‡ºé”™: {e}")
            return Reply(ReplyType.TEXT, "å›¾é›†è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥é“¾æ¥æ˜¯å¦æœ‰æ•ˆ")

    def _make_request(self, method, url, **kwargs):
        """å‘é€HTTPè¯·æ±‚ï¼Œæ”¯æŒé‡è¯•æœºåˆ¶"""
        timeout = self.config["download"]["timeout"]
        max_retries = self.config["download"]["max_retries"]
        retry_delay = self.config["download"]["retry_delay"]
        
        for i in range(max_retries + 1):
            try:
                logger.debug(f"[MediaParser] å‘èµ·è¯·æ±‚: method={method}, url={url}, kwargs={kwargs}")
                
                # ä½¿ç”¨ä¼šè¯å‘é€è¯·æ±‚
                response = self.session.request(
                    method, 
                    url, 
                    timeout=timeout, 
                    **kwargs
                )
                
                # è®°å½•å®Œæ•´çš„å“åº”ä¿¡æ¯
                logger.debug(f"[MediaParser] å“åº”çŠ¶æ€ç : {response.status_code}")
                logger.debug(f"[MediaParser] å“åº”å¤´: {dict(response.headers)}")
                
                # å¦‚æœæ˜¯ JSON è¯·æ±‚ï¼Œè®°å½• JSON å†…å®¹
                try:
                    json_data = response.json()
                    logger.debug(f"[MediaParser] å“åº” JSON: {json_data}")
                except Exception as json_error:
                    logger.debug(f"[MediaParser] è§£æ JSON å¤±è´¥: {json_error}")
                
                # æ£€æŸ¥å“åº”çŠ¶æ€ç 
                if response.status_code == 200:
                    return response
                
                logger.warning(f"[MediaParser] è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                
            except requests.exceptions.RequestException as e:
                logger.warning(f"[MediaParser] è¯·æ±‚å¤±è´¥ï¼Œå°†åœ¨ {retry_delay} ç§’åé‡è¯•ï¼ˆç¬¬ {i+1} æ¬¡ï¼‰: {e}")
                
                if i == max_retries:
                    logger.error(f"[MediaParser] è¯·æ±‚æœ€ç»ˆå¤±è´¥: {e}")
                    return None
                
                time.sleep(retry_delay)
            
            except Exception as e:
                logger.error(f"[MediaParser] æœªçŸ¥é”™è¯¯: {e}")
                return None

    def download_media(self, url, media_type="video"):
        """
        ä¸‹è½½åª’ä½“æ–‡ä»¶ï¼Œæ”¯æŒè§†é¢‘å’Œå›¾ç‰‡
        
        :param url: åª’ä½“æ–‡ä»¶çš„ä¸‹è½½åœ°å€
        :param media_type: åª’ä½“ç±»å‹ï¼Œé»˜è®¤ä¸ºè§†é¢‘
        :return: æ–‡ä»¶å¯¹è±¡å’Œæ–‡ä»¶åï¼Œä¸‹è½½å¤±è´¥è¿”å› (None, None)
        """
        try:
            import os
            import requests
            import mimetypes
            from urllib.parse import urlparse
            
            # æ£€æŸ¥ç¼“å­˜å¤§å°
            self._check_cache_size()
            
            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            parsed_url = urlparse(url)
            file_extension = os.path.splitext(parsed_url.path)[-1] or ('.mp4' if media_type == 'video' else '.jpg')
            filename = f"{int(time.time())}_{hash(url)}{file_extension}"
            filepath = os.path.join(self.cache_dir, filename)
            
            # è®¾ç½®æ›´å¤æ‚çš„è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨è¡Œä¸º
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',
                'Referer': parsed_url.scheme + '://' + parsed_url.netloc,
                'DNT': '1',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1'
            }
            
            # å°è¯•å¤šæ¬¡ä¸‹è½½
            for attempt in range(self.config["download"]["max_retries"]):
                try:
                    response = requests.get(
                        url, 
                        headers=headers, 
                        stream=True, 
                        timeout=self.config["download"]["timeout"]
                    )
                    
                    # æ£€æŸ¥å“åº”çŠ¶æ€ç 
                    if response.status_code == 403:
                        logger.warning(f"[MediaParser] ç¬¬ {attempt + 1} æ¬¡è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : 403")
                        time.sleep(self.config["download"]["retry_delay"])
                        continue
                    
                    response.raise_for_status()  # æŠ›å‡ºå¼‚å¸¸å¤„ç†å…¶ä»–é”™è¯¯çŠ¶æ€ç 
                    
                    # æ£€æµ‹MIMEç±»å‹
                    content_type = response.headers.get('Content-Type', '')
                    logger.info(f"[MediaParser] æ–‡ä»¶MIMEç±»å‹: {content_type}")
                    
                    # å†™å…¥æ–‡ä»¶
                    with open(filepath, 'wb') as f:
                        for chunk in response.iter_content(chunk_size=self.config["cache"]["chunk_size"]):
                            if chunk:
                                f.write(chunk)
                    
                    # æ–‡ä»¶ä¸‹è½½æˆåŠŸ
                    logger.info(f"[MediaParser] æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {filename}")
                    logger.info(f"[MediaParser] æ–‡ä»¶è·¯å¾„: {filepath}")
                    
                    # è¿”å›æ–‡ä»¶å¯¹è±¡
                    return open(filepath, 'rb'), filename
                
                except requests.exceptions.RequestException as e:
                    logger.error(f"[MediaParser] ä¸‹è½½å°è¯• {attempt + 1} å¤±è´¥: {e}")
                    time.sleep(self.config["download"]["retry_delay"])
            
            # å¦‚æœæ‰€æœ‰å°è¯•éƒ½å¤±è´¥
            logger.error("[MediaParser] è§†é¢‘ä¸‹è½½å¤±è´¥ï¼šæ‰€æœ‰é‡è¯•éƒ½æœªæˆåŠŸ")
            return None, None
        
        except Exception as e:
            logger.error(f"[MediaParser] ä¸‹è½½è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", exc_info=True)
            return None, None

    def close_file(self, file_obj):
        """å®‰å…¨åœ°å…³é—­æ–‡ä»¶å¯¹è±¡"""
        try:
            if hasattr(file_obj, '_filepath'):
                filepath = getattr(file_obj, '_filepath')
                if os.path.exists(filepath):
                    try:
                        os.remove(filepath)
                        logger.debug(f"[MediaParser] åˆ é™¤ç¼“å­˜æ–‡ä»¶: {filepath}")
                    except Exception as e:
                        logger.warning(f"[MediaParser] åˆ é™¤ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")
            if hasattr(file_obj, 'close'):
                file_obj.close()
        except Exception as e:
            logger.error(f"[MediaParser] å…³é—­æ–‡ä»¶å¤±è´¥: {e}")

    def _clear_expired_cache(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        try:
            # æ£€æŸ¥ç¼“å­˜ç›®å½•æ˜¯å¦å­˜åœ¨
            if not hasattr(self, 'cache_dir') or not os.path.exists(self.cache_dir):
                logger.warning("[MediaParser] ç¼“å­˜ç›®å½•ä¸å­˜åœ¨")
                return
            
            # æ£€æŸ¥ç¼“å­˜é”æ˜¯å¦å­˜åœ¨
            if not hasattr(self, 'cache_lock'):
                logger.warning("[MediaParser] ç¼“å­˜é”æœªåˆå§‹åŒ–ï¼Œåˆ›å»ºæ–°çš„é”")
                self.cache_lock = threading.Lock()
            
            max_age = self.config["cache"]["max_age_hours"] * 3600
            now = time.time()
            
            with self.cache_lock:
                for f in os.listdir(self.cache_dir):
                    filepath = os.path.join(self.cache_dir, f)
                    try:
                        if os.path.isfile(filepath):
                            file_age = now - os.path.getctime(filepath)
                            if file_age > max_age:
                                try:
                                    os.remove(filepath)
                                    logger.debug(f"[MediaParser] åˆ é™¤è¿‡æœŸæ–‡ä»¶: {f}")
                                except OSError as remove_error:
                                    logger.error(f"[MediaParser] åˆ é™¤æ–‡ä»¶å¤±è´¥: {remove_error}")
                    except Exception as file_error:
                        logger.error(f"[MediaParser] å¤„ç†æ–‡ä»¶ {f} æ—¶å‡ºé”™: {file_error}")
                            
        except Exception as e:
            logger.error(f"[MediaParser] æ¸…ç†è¿‡æœŸç¼“å­˜å¤±è´¥: {e}")
            # å°è¯•é‡æ–°åˆå§‹åŒ–ç¼“å­˜é”
            self.cache_lock = threading.Lock()

    def _check_cache_size(self):
        """æ£€æŸ¥å¹¶æ§åˆ¶ç¼“å­˜å¤§å°"""
        try:
            max_size = self.config["cache"]["max_size_mb"] * 1024 * 1024
            with self.cache_lock:
                files = []
                total_size = 0
                for f in os.listdir(self.cache_dir):
                    filepath = os.path.join(self.cache_dir, f)
                    if os.path.isfile(filepath):
                        size = os.path.getsize(filepath)
                        ctime = os.path.getctime(filepath)
                        files.append((filepath, size, ctime))
                        total_size += size
                        
                if total_size > max_size:
                    # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼Œåˆ é™¤æœ€è€çš„æ–‡ä»¶
                    files.sort(key=lambda x: x[2])
                    
                    for filepath, size, _ in files:
                        try:
                            os.remove(filepath)
                            total_size -= size
                            logger.debug(f"[MediaParser] åˆ é™¤ç¼“å­˜æ–‡ä»¶: {os.path.basename(filepath)}")
                            if total_size <= max_size:
                                break
                        except OSError as e:
                            logger.error(f"[MediaParser] åˆ é™¤æ–‡ä»¶å¤±è´¥: {e}")
                            
        except Exception as e:
            logger.error(f"[MediaParser] æ£€æŸ¥ç¼“å­˜å¤§å°å¤±è´¥: {e}")

    def clean_cache(self):
        """æ¸…ç†æ‰€æœ‰ç¼“å­˜"""
        try:
            with self.cache_lock:
                files = [f for f in os.listdir(self.cache_dir) 
                        if os.path.isfile(os.path.join(self.cache_dir, f))]
                total_size = sum(os.path.getsize(os.path.join(self.cache_dir, f)) 
                               for f in files)
                
                for f in files:
                    try:
                        os.remove(os.path.join(self.cache_dir, f))
                    except OSError as e:
                        logger.error(f"[MediaParser] åˆ é™¤æ–‡ä»¶å¤±è´¥: {e}")
                        
            return f"ç¼“å­˜å·²æ¸…ç†\næ¸…ç†å‰ï¼š{len(files)}ä¸ªæ–‡ä»¶ï¼Œ{self.format_size(total_size)}"
                
        except Exception as e:
            logger.error(f"[MediaParser] æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
            return "æ¸…ç†ç¼“å­˜å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"

    def cache_status(self):
        """è·å–ç¼“å­˜çŠ¶æ€"""
        try:
            with self.cache_lock:
                files = [f for f in os.listdir(self.cache_dir) 
                        if os.path.isfile(os.path.join(self.cache_dir, f))]
                total_size = sum(os.path.getsize(os.path.join(self.cache_dir, f)) 
                               for f in files)
                
                max_size = self.config["cache"]["max_size_mb"]
                max_age = self.config["cache"]["max_age_hours"]
                
                status = f"ç¼“å­˜çŠ¶æ€ï¼š\n"
                status += f"æ–‡ä»¶æ•°ï¼š{len(files)}\n"
                status += f"å ç”¨ç©ºé—´ï¼š{self.format_size(total_size)}\n"
                status += f"æœ€å¤§ç©ºé—´ï¼š{max_size}MB\n"
                status += f"è¿‡æœŸæ—¶é—´ï¼š{max_age}å°æ—¶"
                
                return status
                
        except Exception as e:
            logger.error(f"[MediaParser] è·å–ç¼“å­˜çŠ¶æ€å¤±è´¥: {e}")
            return "è·å–ç¼“å­˜çŠ¶æ€å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"

    def format_size(self, size):
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        units = ['B', 'KB', 'MB', 'GB']
        unit_index = 0
        while size >= 1024 and unit_index < len(units) - 1:
            size /= 1024
            unit_index += 1
        return f"{size:.2f} {units[unit_index]}"

    def _process_pending_tasks(self):
        """åå°çº¿ç¨‹å¤„ç†å¾…å‘é€çš„ä»»åŠ¡"""
        while not self.stop_event.is_set():
            try:
                current_time = time.time()
                tasks_to_remove = []
                
                with self.tasks_lock:
                    for task_id, task in self.processing_tasks.items():
                        if current_time >= task['next_send_time']:
                            # è·å–ä¸‹ä¸€ä¸ªè¦å‘é€çš„å›å¤
                            reply = task['replies'][task['index']]
                            receiver = task['receiver']  # ä»ä»»åŠ¡ä¸­è·å–æ¥æ”¶è€…ä¿¡æ¯
                            
                            try:
                                # å‘é€å›å¤
                                self.send_to_channel(reply, receiver)
                                logger.debug(f"[MediaParser] å‘é€æˆåŠŸ: {reply}")
                                
                                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                                task['index'] += 1
                                if task['index'] >= len(task['replies']):
                                    # æ‰€æœ‰å›å¤éƒ½å·²å‘é€å®Œæˆ
                                    tasks_to_remove.append(task_id)
                                    logger.info(f"[MediaParser] ä»»åŠ¡å®Œæˆ: {task_id}")
                                else:
                                    # è®¾ç½®ä¸‹ä¸€æ¬¡å‘é€æ—¶é—´
                                    task['next_send_time'] = current_time + self.config["batch"]["delay_seconds"]
                                    
                            except Exception as e:
                                logger.error(f"[MediaParser] å‘é€å¤±è´¥: {e}")
                                # å‘é€å¤±è´¥æ—¶ä¹Ÿç§»é™¤ä»»åŠ¡
                                tasks_to_remove.append(task_id)
                    
                    # æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡
                    for task_id in tasks_to_remove:
                        task = self.processing_tasks.pop(task_id)
                        # æ¸…ç†ç›¸å…³çš„æ–‡ä»¶å¯¹è±¡
                        if 'replies' in task:
                            self.clean_up_files(task['replies'])
                
            except Exception as e:
                logger.error(f"[MediaParser] å¤„ç†ä»»åŠ¡å‡ºé”™: {e}")
            
            # çŸ­æš‚ä¼‘çœ ä»¥é¿å…è¿‡åº¦å ç”¨CPU
            time.sleep(0.1)

    def send_reply(self, reply):
        """å‘é€Replyå¯¹è±¡çš„è¾…åŠ©æ–¹æ³•"""
        try:
            # å‡è®¾ context ä¸­åŒ…å« receiver ä¿¡æ¯
            receiver = reply.receiver  # ç¡®ä¿ Reply å¯¹è±¡åŒ…å« receiver å±æ€§
            logger.debug(f"[MediaParser] å‘é€Replyç±»å‹: {reply.type}, å†…å®¹: {reply.content}")
            self.send_to_channel(reply, receiver)
            # å‘é€å®Œæˆåå…³é—­æ–‡ä»¶å¯¹è±¡
            self.clean_up_files([reply])
        except Exception as e:
            logger.error(f"[MediaParser] å‘é€Replyå¤±è´¥: {e}")

    def send_to_channel(self, reply, receiver):
        """å‘é€Replyå¯¹è±¡åˆ°ç›®æ ‡é¢‘é“"""
        try:
            from channel.channel_factory import create_channel
            from bridge.context import Context
            from bridge.reply import ReplyType
            
            # è®°å½•å‘é€å‰çš„è¯¦ç»†ä¿¡æ¯
            logger.info(f"[MediaParser] å‡†å¤‡å‘é€Reply: ç±»å‹={reply.type}, æ¥æ”¶è€…={receiver}")
            
            channel = create_channel("wx")
            if channel:
                # åˆ›å»º Context å¯¹è±¡ï¼Œè®¾ç½®å¿…è¦çš„å‚æ•°
                context = Context()
                context.kwargs = {'receiver': receiver}
                
                # å¦‚æœæ˜¯å›¾ç‰‡æˆ–è§†é¢‘ç±»å‹ï¼Œå…ˆå‘é€æ–‡æœ¬æè¿°
                if reply.type in [ReplyType.IMAGE, ReplyType.VIDEO]:
                    # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„æ–‡æœ¬æè¿°
                    description = getattr(reply, 'text', None)
                    
                    if description and isinstance(description, str):
                        # å…ˆå‘é€æ–‡æœ¬æè¿°
                        text_reply = Reply(ReplyType.TEXT, description)
                        text_reply.receiver = receiver
                        channel.send(text_reply, context)
                        logger.info(f"[MediaParser] å‘é€åª’ä½“æè¿°æ–‡æœ¬: {description}")
                
                # å‘é€åª’ä½“æ–‡ä»¶
                try:
                    channel.send(reply, context)
                    logger.info(f"[MediaParser] é€šè¿‡channelå‘é€åª’ä½“æ–‡ä»¶æˆåŠŸ: {reply}")
                except Exception as send_error:
                    logger.error(f"[MediaParser] channelå‘é€åª’ä½“æ–‡ä»¶å¤±è´¥: {send_error}")
                    # å°è¯•æ‰“å°æ›´å¤šè¯Šæ–­ä¿¡æ¯
                    import traceback
                    logger.error(f"[MediaParser] å‘é€åª’ä½“æ–‡ä»¶é”™è¯¯è¿½è¸ª: {traceback.format_exc()}")
                    raise
            else:
                logger.error("[MediaParser] æœªæ‰¾åˆ°å¾®ä¿¡channel")
                raise RuntimeError("æœªæ‰¾åˆ°å¾®ä¿¡channel")
        
        except Exception as e:
            logger.error(f"[MediaParser] å‘é€åˆ°channelå¤±è´¥: {e}")
            import traceback
            logger.error(f"[MediaParser] è¯¦ç»†é”™è¯¯è¿½è¸ª: {traceback.format_exc()}")
            raise

    def clean_up_files(self, reply_list):
        """åœ¨æ‰€æœ‰å›å¤å‘é€å®Œæˆåå…³é—­æ–‡ä»¶å¯¹è±¡"""
        for reply in reply_list:
            if reply.type in [ReplyType.IMAGE, ReplyType.VIDEO]:
                try:
                    self.close_file(reply.content)
                except Exception as e:
                    logger.error(f"[MediaParser] å…³é—­æ–‡ä»¶å¤±è´¥: {e}")

    def __del__(self):
        """æ¸…ç†èµ„æº"""
        try:
            self.stop_event.set()
            self.worker_thread.join(timeout=5)
            self.session.close()
            self.executor.shutdown(wait=False)
        except Exception as e:
            logger.error(f"[MediaParser] å…³é—­èµ„æºå¤±è´¥: {e}")

import re
import requests
import time
import os
import json
from bridge.reply import Reply, ReplyType
from bridge.context import ContextType, Context
from common.log import logger
from plugins import register, Plugin, Event, EventContext, EventAction
from concurrent.futures import ThreadPoolExecutor
from functools import partial
import hashlib
import threading
from io import BytesIO
from PIL import Image
import io

@register(name="media_parser", desc="è§†é¢‘å›¾é›†è§£ææ’ä»¶", version="1.4", author="å®‰ä¸", desire_priority=100)
class MediaParserPlugin(Plugin):
    def __init__(self):
        super().__init__()
        self.handlers[Event.ON_HANDLE_CONTEXT] = self.on_handle_context
        
        # åˆå§‹åŒ–é…ç½®å’Œç¼“å­˜
        self._load_config()
        self._init_cache()
        
        # åˆå§‹åŒ–ä¼šè¯å’Œçº¿ç¨‹æ± 
        self.session = requests.Session()
        self.executor = ThreadPoolExecutor(max_workers=5)  # å¢åŠ çº¿ç¨‹æ± å¤§å°ä»¥æé«˜ä¸‹è½½æ•ˆç‡
        
        # çº¿ç¨‹é”ç”¨äºç¼“å­˜ç®¡ç†çš„åŒæ­¥
        self.cache_lock = threading.Lock()  # ç¡®ä¿è¿™è¡Œå­˜åœ¨
        self.tasks_lock = threading.Lock()
        
        # æ”¯æŒçš„æ–‡ä»¶ç±»å‹
        self.video_extensions = {
            'video/mp4': '.mp4',
            'video/x-flv': '.flv',
            'video/quicktime': '.mov',
            'video/x-ms-wmv': '.wmv',
            'video/x-msvideo': '.avi',
        }
        
        self.image_extensions = {
            'image/jpeg': '.jpg',
            'image/png': '.png',
            'image/gif': '.gif',
            'image/webp': '.webp',
            'image/bmp': '.bmp',
        }
        
        # è®°å½•æ­£åœ¨å¤„ç†çš„ä»»åŠ¡
        self.processing_tasks = {}
        
        # å¯åŠ¨åå°çº¿ç¨‹å¤„ç†å¾…å‘é€çš„ä»»åŠ¡
        self.stop_event = threading.Event()
        self.worker_thread = threading.Thread(target=self._process_pending_tasks, daemon=True)
        self.worker_thread.start()
        
        logger.info("[MediaParser] æ’ä»¶å·²åŠ è½½")

    def _load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        curdir = os.path.dirname(__file__)
        config_path = os.path.join(curdir, "config.json")
        
        self.default_config = {
            "api_endpoints": {
                "video": "https://www.hhlqilongzhu.cn/api/sp_jx/sp.php",
                "image": "https://www.hhlqilongzhu.cn/api/sp_jx/tuji.php"
            },
            "supported_platforms": [
                "æŠ–éŸ³",
                "å¿«æ‰‹",
                "å¾®åš",
                "å°çº¢ä¹¦"
            ],
            "cache": {
                "max_size_mb": 500,
                "max_age_hours": 24,
                "chunk_size": 8192
            },
            "download": {
                "timeout": 30,
                "max_retries": 3,
                "retry_delay": 1,
                "max_workers": 5
            },
            "batch": {
                "image_limit": 10,  # æ¯æ‰¹æœ€å¤šå‘é€çš„å›¾ç‰‡æ•°
                "delay_seconds": 2   # æ‰¹æ¬¡é—´å»¶è¿Ÿæ—¶é—´
            },
            "max_video_size_mb": 20  # è§†é¢‘æœ€å¤§å¤§å°ï¼ˆMBï¼‰
        }
        
        try:
            if os.path.exists(config_path):
                with open(config_path, "r", encoding="utf-8") as f:
                    config = json.load(f)
                self.config = self._merge_config(self.default_config, config)
            else:
                self.config = self.default_config
                with open(config_path, "w", encoding="utf-8") as f:
                    json.dump(self.config, f, indent=4, ensure_ascii=False)
        except Exception as e:
            logger.warn(f"[MediaParser] åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤é…ç½®")
            self.config = self.default_config
            
        # è®¾ç½®API endpoints
        self.video_api = self.config["api_endpoints"]["video"]
        self.image_api = self.config["api_endpoints"]["image"]
        self.supported_platforms = self.config.get("supported_platforms", [])

        # é…ç½®éªŒè¯
        self._validate_config()

    def _validate_config(self):
        """éªŒè¯é…ç½®æ–‡ä»¶çš„æœ‰æ•ˆæ€§"""
        try:
            assert isinstance(self.config["cache"]["max_size_mb"], (int, float)) and self.config["cache"]["max_size_mb"] > 0, "ç¼“å­˜å¤§å°é…ç½®é”™è¯¯"
            assert isinstance(self.config["cache"]["max_age_hours"], (int, float)) and self.config["cache"]["max_age_hours"] > 0, "ç¼“å­˜è¿‡æœŸæ—¶é—´é…ç½®é”™è¯¯"
            assert isinstance(self.config["download"]["timeout"], (int, float)) and self.config["download"]["timeout"] > 0, "ä¸‹è½½è¶…æ—¶é…ç½®é”™è¯¯"
            assert isinstance(self.config["download"]["max_retries"], int) and self.config["download"]["max_retries"] >= 0, "æœ€å¤§é‡è¯•æ¬¡æ•°é…ç½®é”™è¯¯"
            assert isinstance(self.config["download"]["retry_delay"], (int, float)) and self.config["download"]["retry_delay"] >= 0, "é‡è¯•å»¶è¿Ÿé…ç½®é”™è¯¯"
            assert isinstance(self.config["batch"]["image_limit"], int) and self.config["batch"]["image_limit"] > 0, "å›¾é›†æ‰¹é‡å‘é€é™åˆ¶é…ç½®é”™è¯¯"
            assert isinstance(self.config["batch"]["delay_seconds"], (int, float)) and self.config["batch"]["delay_seconds"] >= 0, "æ‰¹æ¬¡å»¶è¿Ÿæ—¶é—´é…ç½®é”™è¯¯"
            assert isinstance(self.config["max_video_size_mb"], (int, float)) and self.config["max_video_size_mb"] > 0, "è§†é¢‘æœ€å¤§å¤§å°é…ç½®é”™è¯¯"
            logger.info("[MediaParser] é…ç½®æ–‡ä»¶éªŒè¯é€šè¿‡")
        except AssertionError as e:
            logger.error(f"[MediaParser] é…ç½®æ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
            self.config = self.default_config  # å›é€€åˆ°é»˜è®¤é…ç½®

    def _merge_config(self, default, custom):
        """é€’å½’åˆå¹¶é…ç½®"""
        result = default.copy()
        for key, value in custom.items():
            if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                result[key] = self._merge_config(result[key], value)
            else:
                result[key] = value
        return result

    def _init_cache(self):
        """åˆå§‹åŒ–ç¼“å­˜ç›®å½•"""
        curdir = os.path.dirname(__file__)
        self.cache_dir = os.path.join(curdir, "cache")
        if not os.path.exists(self.cache_dir):
            os.makedirs(self.cache_dir)
        
        # å¯åŠ¨æ—¶æ¸…ç†è¿‡æœŸç¼“å­˜ï¼Œä½¿ç”¨åå°çº¿ç¨‹
        threading.Thread(target=self._clear_expired_cache, daemon=True).start()

    def get_help_text(self, **kwargs):
        help_text = "è§†é¢‘/å›¾é›†è§£ææ’ä»¶ä½¿ç”¨è¯´æ˜ï¼š\n"
        help_text += "1. å‘é€ 'è§£æè§†é¢‘ <é“¾æ¥>' è·å–æ— æ°´å°è§†é¢‘\n"
        help_text += "2. å‘é€ 'è§£æå›¾é›† <é“¾æ¥>' è·å–å›¾é›†åŸå›¾\n"
        help_text += "3. å‘é€ 'æ¸…ç†ç¼“å­˜' æ¸…é™¤ä¸´æ—¶æ–‡ä»¶\n"
        help_text += "4. å‘é€ 'æŸ¥çœ‹ç¼“å­˜' æŸ¥çœ‹ç¼“å­˜çŠ¶æ€\n"
        help_text += "\næ”¯æŒæ‰¹é‡å‘é€å›¾ç‰‡ï¼Œæ¯æ‰¹æœ€å¤šå‘é€ {} å¼ \n".format(
            self.config["batch"]["image_limit"])
        if self.supported_platforms:
            help_text += "\næ”¯æŒçš„å¹³å°ï¼š\n"
            help_text += "ã€".join(self.supported_platforms)
        return help_text

    def on_handle_context(self, e_context: EventContext):
        if e_context['context'].type != ContextType.TEXT:
            return

        content = e_context['context'].content.strip()
        logger.info(f"[MediaParser] æ”¶åˆ°æ¶ˆæ¯: {content}")
        
        if content == "æ¸…ç†ç¼“å­˜":
            result = self.clean_cache()
            e_context['reply'] = Reply(ReplyType.TEXT, result)
            e_context.action = EventAction.BREAK_PASS
            return
            
        elif content == "æŸ¥çœ‹ç¼“å­˜":
            result = self.cache_status()
            e_context['reply'] = Reply(ReplyType.TEXT, result)
            e_context.action = EventAction.BREAK_PASS
            return

        # æ£€æŸ¥æ˜¯å¦æ˜¯è§£æå‘½ä»¤
        if content.startswith(("è§£æè§†é¢‘", "è§£æå›¾é›†")):
            command = "è§£æè§†é¢‘" if content.startswith("è§£æè§†é¢‘") else "è§£æå›¾é›†"
            url = content[len(command):].strip()
            
            logger.info(f"[MediaParser] è§£æå‘½ä»¤: {command}, URL: {url}")
            
            if not url:
                e_context['reply'] = Reply(ReplyType.TEXT, f"è¯·æä¾›è¦è§£æçš„é“¾æ¥\nä¾‹å¦‚ï¼š{command} <é“¾æ¥>")
                e_context.action = EventAction.BREAK_PASS
                return

            # è·å–æ¥æ”¶è€…ä¿¡æ¯
            receiver = e_context['context'].kwargs.get('receiver')
            if not receiver:
                logger.error("[MediaParser] æ— æ³•è·å–æ¥æ”¶è€…ä¿¡æ¯")
                e_context['reply'] = Reply(ReplyType.TEXT, "æ— æ³•è·å–æ¥æ”¶è€…ä¿¡æ¯")
                e_context.action = EventAction.BREAK_PASS
                return
            
            logger.info(f"[MediaParser] å¼€å§‹å¤„ç†ï¼Œæ¥æ”¶è€…: {receiver}")
            
            try:
                # æå–é“¾æ¥ä¸­çš„URL
                url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'
                urls = re.findall(url_pattern, url)
                
                if not urls:
                    # å°è¯•ä»æ–‡æœ¬ä¸­æå–åˆ†äº«é“¾æ¥
                    share_pattern = r'å¤åˆ¶æ‰“å¼€æŠ–éŸ³|å¿«æ‰‹|å¾®åš|å°çº¢ä¹¦.*?(?:https?://[^\s]+)'
                    share_match = re.search(share_pattern, url)
                    if share_match:
                        share_text = share_match.group(0)
                        urls = re.findall(url_pattern, share_text)
                
                if not urls:
                    logger.error(f"[MediaParser] æœªæ‰¾åˆ°æœ‰æ•ˆé“¾æ¥: {url}")
                    e_context['reply'] = Reply(ReplyType.TEXT, "æœªæ‰¾åˆ°æœ‰æ•ˆçš„é“¾æ¥ï¼Œè¯·ç¡®ä¿é“¾æ¥æ ¼å¼æ­£ç¡®")
                    e_context.action = EventAction.BREAK_PASS
                    return
                
                target_url = urls[0]
                logger.info(f"[MediaParser] æå–åˆ°é“¾æ¥: {target_url}")
                
                if command == "è§£æè§†é¢‘":
                    replies = self.parse_video(target_url)
                else:
                    task_id = f"{receiver}_{int(time.time())}"
                    replies = self.parse_images(target_url, task_id)
                
                # ç¡®ä¿å›å¤è¢«æ­£ç¡®å‘é€
                if isinstance(replies, list) and replies:
                    # å°†ç¬¬ä¸€ä¸ªå›å¤è®¾ç½®ä¸ºä¸»å›å¤
                    e_context['reply'] = replies[0]
                    # å¦‚æœæœ‰æ›´å¤šå›å¤ï¼Œåˆ™å°†å®ƒä»¬æ·»åŠ åˆ°reply_listä¸­
                    if len(replies) > 1:
                        for reply in replies[1:]:
                            self.send_to_channel(reply, receiver)
                else:
                    # å¦‚æœåªæœ‰ä¸€ä¸ªå›å¤æˆ–æ²¡æœ‰å›å¤
                    e_context['reply'] = replies if replies else Reply(ReplyType.TEXT, "è§£æå¤±è´¥")
                
            except Exception as e:
                logger.error(f"[MediaParser] è§£æå¤±è´¥: {e}", exc_info=True)
                e_context['reply'] = Reply(ReplyType.TEXT, "è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥é“¾æ¥æ˜¯å¦æœ‰æ•ˆ")

            e_context.action = EventAction.BREAK_PASS
            return

    def parse_video(self, url):
        """è§£æè§†é¢‘é“¾æ¥"""
        try:
            # ä½¿ç”¨æ–°çš„èšåˆè§£æAPI
            video_api = "https://www.hhlqilongzhu.cn/api/sp_jx/sp.php"
            params = {"url": url}
            
            response = self._make_request("GET", video_api, params=params)
            
            if not response or response.status_code != 200:
                msg = f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}" if response else "APIæ— å“åº”"
                logger.error(f"[MediaParser] è§†é¢‘è§£æAPIè¯·æ±‚å¤±è´¥: {msg}")
                return [Reply(ReplyType.TEXT, msg)]
            
            # è§£æå“åº”å†…å®¹
            data = response.json()
            if data.get("code") != 200:
                error_msg = data.get("msg", "è§†é¢‘è§£æå¤±è´¥")
                logger.error(f"[MediaParser] è§†é¢‘è§£æå¤±è´¥: {error_msg}")
                return [Reply(ReplyType.TEXT, error_msg)]
            
            video_data = data.get("data", {})
            if not video_data:
                logger.error("[MediaParser] æœªè·å–åˆ°è§†é¢‘ä¿¡æ¯")
                return [Reply(ReplyType.TEXT, "æœªè·å–åˆ°è§†é¢‘ä¿¡æ¯")]

            video_url = video_data.get("url")
            if not video_url:
                logger.error("[MediaParser] æœªæ‰¾åˆ°è§†é¢‘åœ°å€")
                return [Reply(ReplyType.TEXT, "æœªæ‰¾åˆ°è§†é¢‘åœ°å€")]
            
            self._check_cache_size()
            file_obj, filename = self.download_media(video_url, "video")
            if not file_obj:
                logger.error("[MediaParser] è§†é¢‘ä¸‹è½½å¤±è´¥")
                return [Reply(ReplyType.TEXT, "è§†é¢‘ä¸‹è½½å¤±è´¥")]
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°å¹¶è¿”å›æç¤ºæ¶ˆæ¯
            file_size = os.path.getsize(os.path.join(self.cache_dir, filename))
            max_size = self.config["max_video_size_mb"] * 1024 * 1024
            if file_size > max_size:
                logger.info(f"[MediaParser] è§†é¢‘å¤§å°ä¸º {file_size/(1024*1024):.2f}MBï¼Œè¿”å›æç¤ºæ¶ˆæ¯")
                file_obj.close()
                return [Reply(ReplyType.TEXT, f"æŠ±æ­‰ï¼Œè¯¥è§†é¢‘æ–‡ä»¶å¤§äº{self.config['max_video_size_mb']}MBï¼Œæš‚æ—¶æ— æ³•å¤„ç†ã€‚è¯·å°è¯•åˆ†äº«è¾ƒå°çš„è§†é¢‘æ–‡ä»¶ã€‚")]
            
            # æ„å»ºè¯¦ç»†çš„è§†é¢‘æè¿°
            description_parts = []
            
            # æ·»åŠ æ ‡é¢˜
            if video_data.get("title"):
                description_parts.append(f"ğŸ¬ æ ‡é¢˜ï¼š{video_data['title']}")
            
            # æ·»åŠ ä½œè€…ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            if video_data.get("author"):
                description_parts.append(f"ğŸ‘¤ ä½œè€…ï¼š{video_data['author']}")
            
            # æ·»åŠ æ–‡æœ¬ä¿¡æ¯
            text_info = data.get("text", {})
            if text_info:
                description_parts.append(f"ğŸ“ ä¿¡æ¯ï¼š{text_info.get('msg', '')}")
                description_parts.append(f"ğŸ•’ æ—¶é—´ï¼š{text_info.get('time', '')}")
            
            # ç»„åˆæè¿°
            description = "\n".join(description_parts)
            
            # åˆ›å»ºå›å¤åˆ—è¡¨
            replies = []
            
            # æ·»åŠ æè¿°æ–‡æœ¬å›å¤
            if description_parts:
                text_reply = Reply(ReplyType.TEXT, description)
                replies.append(text_reply)
            
            # æ·»åŠ è§†é¢‘å›å¤
            video_reply = Reply(ReplyType.VIDEO, file_obj)
            video_reply.filename = filename
            replies.append(video_reply)
            
            logger.info(f"[MediaParser] è§†é¢‘è§£ææˆåŠŸï¼Œæè¿°ï¼š{description}")
            
            return replies
        
        except Exception as e:
            logger.error(f"[MediaParser] è§†é¢‘è§£æå‡ºé”™: {e}", exc_info=True)
            return [Reply(ReplyType.TEXT, "è§†é¢‘è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥é“¾æ¥æ˜¯å¦æœ‰æ•ˆ")]

    def parse_images(self, url, task_id):
        """è§£æå›¾é›†é“¾æ¥"""
        try:
            # ä½¿ç”¨æ–°çš„èšåˆè§£æå›¾é›†API
            images_api = "https://www.hhlqilongzhu.cn/api/sp_jx/tuji.php"
            params = {"url": url}
            
            response = self._make_request("GET", images_api, params=params)
            
            if not response or response.status_code != 200:
                msg = f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}" if response else "APIæ— å“åº”"
                return Reply(ReplyType.TEXT, msg)
            
            # è§£æå“åº”å†…å®¹
            data = response.json()
            if data.get("code") != 200:
                return Reply(ReplyType.TEXT, data.get("msg", "å›¾é›†è§£æå¤±è´¥"))
            
            image_data = data.get("data", {})
            images = image_data.get("images", [])
            
            if not images:
                return Reply(ReplyType.TEXT, "æœªæ‰¾åˆ°å›¾ç‰‡")
            
            # è®°å½•å›¾ç‰‡æ•°é‡
            logger.info(f"[MediaParser] è·å–åˆ° {len(images)} å¼ å›¾ç‰‡çš„URL")
            
            # å‡†å¤‡å‘é€çš„å›¾ç‰‡åˆ—è¡¨
            image_replies = []
            
            # æ„å»ºè¯¦ç»†çš„å›¾é›†æè¿°
            description_parts = []
            
            # æ·»åŠ ä½œè€…
            if image_data.get("author"):
                description_parts.append(f"ğŸ‘¤ ä½œè€…ï¼š{image_data['author']}")
            
            # æ·»åŠ æ ‡é¢˜
            if image_data.get("title"):
                description_parts.append(f"ğŸ–¼ï¸ æ ‡é¢˜ï¼š{image_data['title']}")
            
            # æ·»åŠ æ–‡æœ¬ä¿¡æ¯
            text_info = image_data.get("text", {})
            if text_info:
                description_parts.append(f"ğŸ“ ä¿¡æ¯ï¼š{text_info.get('msg', '')}")
                description_parts.append(f"ğŸ•’ æ—¶é—´ï¼š{text_info.get('time', '')}")
            
            # ç»„åˆæè¿°
            description = "\n".join(description_parts)
            
            # å‘é€æè¿°æ–‡æœ¬
            if description_parts:
                text_reply = Reply(ReplyType.TEXT, description)
                text_reply.receiver = task_id
                image_replies.append(text_reply)
            
            # ä¸‹è½½å¹¶å‘é€å›¾ç‰‡
            for index, img_url in enumerate(images, 1):
                self._check_cache_size()
                file_obj, filename = self.download_media(img_url, "image")
                
                if file_obj:
                    # ä¸ºæ¯å¼ å›¾ç‰‡åˆ›å»ºå•ç‹¬çš„å›¾ç‰‡æè¿°
                    image_description = f"ğŸ“¸ å›¾ç‰‡ {index}/{len(images)}"
                    
                    # åˆ›å»ºæ–‡æœ¬å›å¤
                    text_reply = Reply(ReplyType.TEXT, image_description)
                    text_reply.receiver = task_id
                    
                    # åˆ›å»ºå›¾ç‰‡å›å¤
                    image_reply = Reply(ReplyType.IMAGE, file_obj)
                    image_reply.filename = filename
                    image_reply.receiver = task_id
                    
                    # åˆ†åˆ«å‘é€æ–‡æœ¬å’Œå›¾ç‰‡
                    image_replies.extend([text_reply, image_reply])
            
            # å‘é€å®Œæˆæç¤º
            complete_reply = Reply(ReplyType.TEXT, f"å›¾é›†å‘é€å®Œæˆï¼Œå…± {len(images)} å¼ å›¾ç‰‡")
            complete_reply.receiver = task_id
            image_replies.append(complete_reply)
            
            return image_replies
        
        except Exception as e:
            logger.error(f"[MediaParser] å›¾é›†è§£æå‡ºé”™: {e}")
            return Reply(ReplyType.TEXT, "å›¾é›†è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥é“¾æ¥æ˜¯å¦æœ‰æ•ˆ")

    def _make_request(self, method, url, **kwargs):
        """å‘é€HTTPè¯·æ±‚ï¼Œæ”¯æŒé‡è¯•æœºåˆ¶"""
        timeout = self.config["download"]["timeout"]
        max_retries = self.config["download"]["max_retries"]
        retry_delay = self.config["download"]["retry_delay"]
        
        for i in range(max_retries + 1):
            try:
                logger.debug(f"[MediaParser] å‘èµ·è¯·æ±‚: method={method}, url={url}, kwargs={kwargs}")
                
                # ä½¿ç”¨ä¼šè¯å‘é€è¯·æ±‚
                response = self.session.request(
                    method, 
                    url, 
                    timeout=timeout, 
                    **kwargs
                )
                
                # è®°å½•å®Œæ•´çš„å“åº”ä¿¡æ¯
                logger.debug(f"[MediaParser] å“åº”çŠ¶æ€ç : {response.status_code}")
                logger.debug(f"[MediaParser] å“åº”å¤´: {dict(response.headers)}")
                
                # å¦‚æœæ˜¯ JSON è¯·æ±‚ï¼Œè®°å½• JSON å†…å®¹
                if not kwargs.get('stream'):  # åªåœ¨éæµå¼è¯·æ±‚æ—¶å°è¯•è§£æJSON
                    try:
                        json_data = response.json()
                        logger.debug(f"[MediaParser] å“åº” JSON: {json_data}")
                    except Exception as json_error:
                        logger.debug(f"[MediaParser] è§£æ JSON å¤±è´¥: {json_error}")
                
                # æ£€æŸ¥å“åº”çŠ¶æ€ç 
                if response.status_code == 200:
                    return response
                
                logger.warning(f"[MediaParser] è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                
            except requests.exceptions.RequestException as e:
                logger.warning(f"[MediaParser] è¯·æ±‚å¤±è´¥ï¼Œå°†åœ¨ {retry_delay} ç§’åé‡è¯•ï¼ˆç¬¬ {i+1} æ¬¡ï¼‰: {e}")
                
                if i == max_retries:
                    logger.error(f"[MediaParser] è¯·æ±‚æœ€ç»ˆå¤±è´¥: {e}")
                    return None
                
                time.sleep(retry_delay)
            
            except Exception as e:
                logger.error(f"[MediaParser] æœªçŸ¥é”™è¯¯: {e}")
                return None

    def download_media(self, url, media_type="video"):
        """ä¸‹è½½åª’ä½“æ–‡ä»¶ï¼Œæ”¯æŒè§†é¢‘å’Œå›¾ç‰‡"""
        try:
            logger.info(f"[MediaParser] å¼€å§‹ä¸‹è½½{media_type}: {url}")
            response = self._make_request("GET", url, stream=True)
            if not response:
                logger.error(f"[MediaParser] ä¸‹è½½å¤±è´¥: æ— æ³•è·å–å“åº”")
                return None, None

            # è·å–Content-Typeå’Œæ–‡ä»¶å¤§å°
            content_type = response.headers.get('content-type', '').lower()
            content_length = response.headers.get('content-length')
            logger.info(f"[MediaParser] æ–‡ä»¶MIMEç±»å‹: {content_type}, é¢„æœŸå¤§å°: {content_length} bytes")
            
            # éªŒè¯Content-Type
            if media_type == "video" and content_type not in self.video_extensions:
                logger.error(f"[MediaParser] ä¸æ”¯æŒçš„è§†é¢‘ç±»å‹: {content_type}")
                return None, None
            elif media_type == "image" and content_type not in self.image_extensions:
                logger.error(f"[MediaParser] ä¸æ”¯æŒçš„å›¾ç‰‡ç±»å‹: {content_type}")
                return None, None

            # æ ¹æ®åª’ä½“ç±»å‹é€‰æ‹©æ‰©å±•å
            if media_type == "video":
                extension = self.video_extensions.get(content_type, '.mp4')
            else:
                extension = self.image_extensions.get(content_type, '.jpg')

            # ä½¿ç”¨æ—¶é—´æˆ³å’Œéšæœºæ•°ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            filename = f"{int(time.time())}_{hash(url)}{extension}"
            filepath = os.path.join(self.cache_dir, filename)

            # ä½¿ç”¨äºŒè¿›åˆ¶æ¨¡å¼å†™å…¥æ–‡ä»¶
            total_size = 0
            with open(filepath, 'wb') as f:
                for chunk in response.iter_content(chunk_size=self.config["cache"]["chunk_size"]):
                    if chunk:
                        f.write(chunk)
                        total_size += len(chunk)

            logger.info(f"[MediaParser] æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {filename}")
            logger.info(f"[MediaParser] æ–‡ä»¶è·¯å¾„: {filepath}")
            logger.info(f"[MediaParser] æ–‡ä»¶å¤§å°: {self.format_size(total_size)}")

            # ç¡®ä¿æ–‡ä»¶æƒé™æ­£ç¡®
            try:
                os.chmod(filepath, 0o644)
            except Exception as e:
                logger.warning(f"[MediaParser] è®¾ç½®æ–‡ä»¶æƒé™å¤±è´¥: {e}")

            # æ‰“å¼€æ–‡ä»¶ç”¨äºè¯»å–
            file_obj = open(filepath, 'rb')
            return file_obj, filename

        except Exception as e:
            logger.error(f"[MediaParser] ä¸‹è½½åª’ä½“æ–‡ä»¶å¤±è´¥: {e}")
            import traceback
            logger.error(f"[MediaParser] é”™è¯¯è¿½è¸ª: {traceback.format_exc()}")
            return None, None

    def close_file(self, file_obj):
        """å®‰å…¨åœ°å…³é—­æ–‡ä»¶å¯¹è±¡"""
        try:
            if hasattr(file_obj, '_filepath'):
                filepath = getattr(file_obj, '_filepath')
                if os.path.exists(filepath):
                    try:
                        os.remove(filepath)
                        logger.debug(f"[MediaParser] åˆ é™¤ç¼“å­˜æ–‡ä»¶: {filepath}")
                    except Exception as e:
                        logger.warning(f"[MediaParser] åˆ é™¤ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")
            if hasattr(file_obj, 'close'):
                file_obj.close()
        except Exception as e:
            logger.error(f"[MediaParser] å…³é—­æ–‡ä»¶å¤±è´¥: {e}")

    def _clear_expired_cache(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        try:
            logger.info("[MediaParser] å¼€å§‹æ¸…ç†è¿‡æœŸç¼“å­˜")
            max_age = self.config["cache"]["max_age_hours"] * 3600  # è½¬æ¢ä¸ºç§’
            current_time = time.time()
            removed_count = 0
            removed_size = 0
            
            for filename in os.listdir(self.cache_dir):
                filepath = os.path.join(self.cache_dir, filename)
                if os.path.isfile(filepath):
                    # æ£€æŸ¥æ–‡ä»¶å¹´é¾„
                    file_age = current_time - os.path.getctime(filepath)
                    if file_age > max_age:
                        try:
                            size = os.path.getsize(filepath)
                            os.remove(filepath)
                            removed_count += 1
                            removed_size += size
                            logger.info(f"[MediaParser] åˆ é™¤è¿‡æœŸæ–‡ä»¶: {filepath}, å¹´é¾„: {int(file_age/3600)}å°æ—¶")
                        except Exception as e:
                            logger.error(f"[MediaParser] åˆ é™¤è¿‡æœŸæ–‡ä»¶å¤±è´¥: {filepath}, é”™è¯¯: {e}")
            
            if removed_count > 0:
                logger.info(f"[MediaParser] æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {removed_count} ä¸ªæ–‡ä»¶ï¼Œæ€»å¤§å°: {self.format_size(removed_size)}")
            else:
                logger.info("[MediaParser] æ²¡æœ‰å‘ç°è¿‡æœŸæ–‡ä»¶")
                
        except Exception as e:
            logger.error(f"[MediaParser] æ¸…ç†è¿‡æœŸç¼“å­˜å¤±è´¥: {e}", exc_info=True)

    def _check_cache_size(self):
        """æ£€æŸ¥å¹¶æ§åˆ¶ç¼“å­˜å¤§å°"""
        try:
            logger.info("[MediaParser] å¼€å§‹æ£€æŸ¥ç¼“å­˜å¤§å°")
            total_size = 0
            files = []
            
            # è·å–æ‰€æœ‰ç¼“å­˜æ–‡ä»¶ä¿¡æ¯
            for filename in os.listdir(self.cache_dir):
                filepath = os.path.join(self.cache_dir, filename)
                if os.path.isfile(filepath):
                    size = os.path.getsize(filepath)
                    ctime = os.path.getctime(filepath)
                    files.append((filepath, size, ctime))
                    total_size += size
            
            max_size = self.config["cache"]["max_size_mb"] * 1024 * 1024  # è½¬æ¢ä¸ºå­—èŠ‚
            logger.info(f"[MediaParser] å½“å‰ç¼“å­˜å¤§å°: {self.format_size(total_size)}, æœ€å¤§é™åˆ¶: {self.format_size(max_size)}")
            
            if total_size > max_size:
                # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼Œåˆ é™¤æœ€æ—§çš„æ–‡ä»¶
                files.sort(key=lambda x: x[2])  # æŒ‰åˆ›å»ºæ—¶é—´æ’åº
                
                # åˆ é™¤æ–‡ä»¶ç›´åˆ°ç¼“å­˜å¤§å°å°äºé™åˆ¶
                while total_size > max_size and files:
                    filepath, size, _ = files.pop(0)
                    try:
                        os.remove(filepath)
                        total_size -= size
                        logger.info(f"[MediaParser] åˆ é™¤ç¼“å­˜æ–‡ä»¶: {filepath}, å¤§å°: {self.format_size(size)}")
                    except Exception as e:
                        logger.error(f"[MediaParser] åˆ é™¤ç¼“å­˜æ–‡ä»¶å¤±è´¥: {filepath}, é”™è¯¯: {e}")
                
                logger.info(f"[MediaParser] æ¸…ç†åçš„ç¼“å­˜å¤§å°: {self.format_size(total_size)}")
            
        except Exception as e:
            logger.error(f"[MediaParser] æ£€æŸ¥ç¼“å­˜å¤§å°å¤±è´¥: {e}", exc_info=True)
            
    def clean_cache(self):
        """æ¸…ç†æ‰€æœ‰ç¼“å­˜"""
        try:
            with self.cache_lock:
                files = [f for f in os.listdir(self.cache_dir) 
                        if os.path.isfile(os.path.join(self.cache_dir, f))]
                total_size = sum(os.path.getsize(os.path.join(self.cache_dir, f)) 
                               for f in files)
                
                for f in files:
                    try:
                        os.remove(os.path.join(self.cache_dir, f))
                    except OSError as e:
                        logger.error(f"[MediaParser] åˆ é™¤æ–‡ä»¶å¤±è´¥: {e}")
                        
            return f"ç¼“å­˜å·²æ¸…ç†\næ¸…ç†å‰ï¼š{len(files)}ä¸ªæ–‡ä»¶ï¼Œ{self.format_size(total_size)}"
                
        except Exception as e:
            logger.error(f"[MediaParser] æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
            return "æ¸…ç†ç¼“å­˜å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"

    def cache_status(self):
        """è·å–ç¼“å­˜çŠ¶æ€"""
        try:
            with self.cache_lock:
                files = [f for f in os.listdir(self.cache_dir) 
                        if os.path.isfile(os.path.join(self.cache_dir, f))]
                total_size = sum(os.path.getsize(os.path.join(self.cache_dir, f)) 
                               for f in files)
                
                max_size = self.config["cache"]["max_size_mb"]
                max_age = self.config["cache"]["max_age_hours"]
                
                status = f"ç¼“å­˜çŠ¶æ€ï¼š\n"
                status += f"æ–‡ä»¶æ•°ï¼š{len(files)}\n"
                status += f"å ç”¨ç©ºé—´ï¼š{self.format_size(total_size)}\n"
                status += f"æœ€å¤§ç©ºé—´ï¼š{max_size}MB\n"
                status += f"è¿‡æœŸæ—¶é—´ï¼š{max_age}å°æ—¶"
                
                return status
                
        except Exception as e:
            logger.error(f"[MediaParser] è·å–ç¼“å­˜çŠ¶æ€å¤±è´¥: {e}")
            return "è·å–ç¼“å­˜çŠ¶æ€å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"

    def format_size(self, size):
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        units = ['B', 'KB', 'MB', 'GB']
        unit_index = 0
        while size >= 1024 and unit_index < len(units) - 1:
            size /= 1024
            unit_index += 1
        return f"{size:.2f} {units[unit_index]}"

    def _process_pending_tasks(self):
        """åå°çº¿ç¨‹å¤„ç†å¾…å‘é€çš„ä»»åŠ¡"""
        while not self.stop_event.is_set():
            try:
                current_time = time.time()
                tasks_to_remove = []
                
                with self.tasks_lock:
                    for task_id, task in self.processing_tasks.items():
                        if current_time >= task['next_send_time']:
                            # è·å–ä¸‹ä¸€ä¸ªè¦å‘é€çš„å›å¤
                            reply = task['replies'][task['index']]
                            receiver = task['receiver']  # ä»ä»»åŠ¡ä¸­è·å–æ¥æ”¶è€…ä¿¡æ¯
                            
                            try:
                                # å‘é€å›å¤
                                self.send_to_channel(reply, receiver)
                                logger.debug(f"[MediaParser] å‘é€æˆåŠŸ: {reply}")
                                
                                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                                task['index'] += 1
                                if task['index'] >= len(task['replies']):
                                    # æ‰€æœ‰å›å¤éƒ½å·²å‘é€å®Œæˆ
                                    tasks_to_remove.append(task_id)
                                    logger.info(f"[MediaParser] ä»»åŠ¡å®Œæˆ: {task_id}")
                                else:
                                    # è®¾ç½®ä¸‹ä¸€æ¬¡å‘é€æ—¶é—´
                                    task['next_send_time'] = current_time + self.config["batch"]["delay_seconds"]
                                    
                            except Exception as e:
                                logger.error(f"[MediaParser] å‘é€å¤±è´¥: {e}")
                                # å‘é€å¤±è´¥æ—¶ä¹Ÿç§»é™¤ä»»åŠ¡
                                tasks_to_remove.append(task_id)
                    
                    # æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡
                    for task_id in tasks_to_remove:
                        task = self.processing_tasks.pop(task_id)
                        # æ¸…ç†ç›¸å…³çš„æ–‡ä»¶å¯¹è±¡
                        if 'replies' in task:
                            self.clean_up_files(task['replies'])
                
            except Exception as e:
                logger.error(f"[MediaParser] å¤„ç†ä»»åŠ¡å‡ºé”™: {e}")
            
            # çŸ­æš‚ä¼‘çœ ä»¥é¿å…è¿‡åº¦å ç”¨CPU
            time.sleep(0.1)

    def send_reply(self, reply):
        """å‘é€Replyå¯¹è±¡çš„è¾…åŠ©æ–¹æ³•"""
        try:
            # å‡è®¾ context ä¸­åŒ…å« receiver ä¿¡æ¯
            receiver = reply.receiver  # ç¡®ä¿ Reply å¯¹è±¡åŒ…å« receiver å±æ€§
            logger.debug(f"[MediaParser] å‘é€Replyç±»å‹: {reply.type}, å†…å®¹: {reply.content}")
            self.send_to_channel(reply, receiver)
            # å‘é€å®Œæˆåå…³é—­æ–‡ä»¶å¯¹è±¡
            self.clean_up_files([reply])
        except Exception as e:
            logger.error(f"[MediaParser] å‘é€Replyå¤±è´¥: {e}")

    def send_to_channel(self, reply, receiver):
        """å‘é€Replyå¯¹è±¡åˆ°ç›®æ ‡é¢‘é“"""
        try:
            from channel.channel_factory import create_channel
            from bridge.context import Context
            from bridge.reply import ReplyType
            
            logger.info(f"[MediaParser] å‡†å¤‡å‘é€Reply: ç±»å‹={reply.type}, æ¥æ”¶è€…={receiver}")
            
            channel = create_channel("wx")
            if channel:
                context = Context()
                context.kwargs = {'receiver': receiver}
                
                if reply.type in [ReplyType.IMAGE, ReplyType.VIDEO]:
                    # ç¡®ä¿æ–‡ä»¶å­˜åœ¨ä¸”å¯è¯»
                    if hasattr(reply.content, 'name'):
                        if not os.path.exists(reply.content.name):
                            logger.error(f"[MediaParser] æ–‡ä»¶ä¸å­˜åœ¨: {reply.content.name}")
                            return
                        
                        # é‡æ–°æ‰“å¼€æ–‡ä»¶ä»¥ç¡®ä¿å®ƒæ˜¯å¯è¯»çš„
                        try:
                            reply.content.close()
                            reply.content = open(reply.content.name, 'rb')
                        except Exception as e:
                            logger.error(f"[MediaParser] é‡æ–°æ‰“å¼€æ–‡ä»¶å¤±è´¥: {e}")
                            return
                
                try:
                    channel.send(reply, context)
                    logger.info(f"[MediaParser] å‘é€æˆåŠŸ: {reply}")
                except Exception as send_error:
                    logger.error(f"[MediaParser] å‘é€å¤±è´¥: {send_error}")
                    import traceback
                    logger.error(f"[MediaParser] é”™è¯¯è¿½è¸ª: {traceback.format_exc()}")
                finally:
                    # ç¡®ä¿æ–‡ä»¶è¢«å…³é—­
                    if reply.type in [ReplyType.IMAGE, ReplyType.VIDEO]:
                        try:
                            reply.content.close()
                        except:
                            pass
            else:
                logger.error("[MediaParser] æœªæ‰¾åˆ°å¾®ä¿¡channel")
                raise RuntimeError("æœªæ‰¾åˆ°å¾®ä¿¡channel")
        
        except Exception as e:
            logger.error(f"[MediaParser] å‘é€å¤±è´¥: {e}")
            import traceback
            logger.error(f"[MediaParser] é”™è¯¯è¿½è¸ª: {traceback.format_exc()}")

    def clean_up_files(self, reply_list):
        """åœ¨æ‰€æœ‰å›å¤å‘é€å®Œæˆåå…³é—­æ–‡ä»¶å¯¹è±¡"""
        for reply in reply_list:
            if reply.type in [ReplyType.IMAGE, ReplyType.VIDEO]:
                try:
                    self.close_file(reply.content)
                except Exception as e:
                    logger.error(f"[MediaParser] å…³é—­æ–‡ä»¶å¤±è´¥: {e}")

    def __del__(self):
        """æ¸…ç†èµ„æº"""
        try:
            self.stop_event.set()
            self.worker_thread.join(timeout=5)
            self.session.close()
            self.executor.shutdown(wait=False)
        except Exception as e:
            logger.error(f"[MediaParser] å…³é—­èµ„æºå¤±è´¥: {e}")
